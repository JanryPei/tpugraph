{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef62882",
   "metadata": {
    "papermill": {
     "duration": 0.021175,
     "end_time": "2023-09-26T07:46:27.102252",
     "exception": false,
     "start_time": "2023-09-26T07:46:27.081077",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Predict AI Model Runtimes ðŸ¤–ðŸ’¨\n",
    "\n",
    "## Introduction ðŸŒŸ\n",
    "Welcome to this Jupyter notebook developed for the Google - Fast or Slow? Predict AI Model Runtime! This notebook is designed to help you participate in the competition and to Detect sleep onset and wake from wrist-worn accelerometer data.\n",
    "\n",
    "### Inspiration and Credits ðŸ™Œ\n",
    "This notebook is inspired by the work of Bhukya Satheesh\n",
    ", available at [this Kaggle project](https://www.kaggle.com/code/satheeshbhukya1/google-fast-or-slow/notebook). I extend my gratitude to Bhukya Satheesh\n",
    " for sharing their insights and code.\n",
    "\n",
    "ðŸŒŸ Explore my profile and other public projects, and don't forget to share your feedback! \n",
    "ðŸ‘‰ [Visit my Profile](https://www.kaggle.com/zulqarnainali) ðŸ‘ˆ\n",
    "\n",
    "ðŸ™ Thank you for taking the time to review my work, and please give it a thumbs-up if you found it valuable! ðŸ‘\n",
    "\n",
    "## Purpose ðŸŽ¯\n",
    "The primary purpose of this notebook is to:\n",
    "- Load and preprocess the competition data ðŸ“\n",
    "- Engineer relevant features for model training ðŸ‹ï¸â€â™‚ï¸\n",
    "- Train predictive models to make target variable predictions ðŸ§ \n",
    "- Submit predictions to the competition environment ðŸ“¤\n",
    "\n",
    "## Notebook Structure ðŸ“š\n",
    "This notebook is structured as follows:\n",
    "1. **Data Preparation**: In this section, we load and preprocess the competition data.\n",
    "2. **Feature Engineering**: We generate and select relevant features for model training.\n",
    "3. **Model Training**: We train machine learning models on the prepared data.\n",
    "4. **Prediction and Submission**: We make predictions on the test data and submit them for evaluation.\n",
    "\n",
    "\n",
    "## How to Use ðŸ› ï¸\n",
    "To use this notebook effectively, please follow these steps:\n",
    "1. Ensure you have the competition data and environment set up.\n",
    "2. Execute each cell sequentially to perform data preparation, feature engineering, model training, and prediction submission.\n",
    "3. Customize and adapt the code as needed to improve model performance or experiment with different approaches.\n",
    "\n",
    "**Note**: Make sure to replace any placeholder paths or configurations with your specific information.\n",
    "\n",
    "## Acknowledgments ðŸ™\n",
    "We acknowledge theChild Mind Institute\n",
    " organizers for providing the dataset and the competition platform.\n",
    "\n",
    "Let's get started! Feel free to reach out if you have any questions or need assistance along the way.\n",
    "ðŸ‘‰ [Visit my Profile](https://www.kaggle.com/zulqarnainali) ðŸ‘ˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f3bb09",
   "metadata": {
    "papermill": {
     "duration": 0.020771,
     "end_time": "2023-09-26T07:46:27.143822",
     "exception": false,
     "start_time": "2023-09-26T07:46:27.123051",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ðŸ“¦ Importing necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2cbe15f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:46:27.188437Z",
     "iopub.status.busy": "2023-09-26T07:46:27.187390Z",
     "iopub.status.idle": "2023-09-26T07:46:50.817370Z",
     "shell.execute_reply": "2023-09-26T07:46:50.816053Z"
    },
    "papermill": {
     "duration": 23.655525,
     "end_time": "2023-09-26T07:46:50.820471",
     "exception": false,
     "start_time": "2023-09-26T07:46:27.164946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ðŸ“š Importing  libraries\n",
    "import os  # For interacting with the operating system\n",
    "from pathlib import Path  # For working with file paths\n",
    "from typing import Dict, Optional, List, Union, Tuple  # For defining data types\n",
    "from dataclasses import dataclass  # For creating data classes\n",
    "import math  # For mathematical operations\n",
    "import numpy as np  # For numerical computations\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "from datasets import Dataset  # For handling datasets\n",
    "from tqdm import tqdm  # For progress tracking\n",
    "import torch  # For deep learning with PyTorch\n",
    "from torch import nn  # For neural network modules\n",
    "from torch.nn import functional as F  # For various functions used in neural networks\n",
    "from torch.nn.utils.rnn import pad_sequence  # For padding sequences\n",
    "from torch.utils.data import DataLoader  # For creating data loaders\n",
    "from transformers.modeling_outputs import BaseModelOutputWithPastAndCrossAttentions  # For transformer model outputs\n",
    "from transformers.pytorch_utils import apply_chunking_to_forward  # For handling chunking during model forward pass\n",
    "from transformers.activations import ACT2FN  # For transformer activations\n",
    "import pytorch_lightning as pl  # For PyTorch Lightning, a useful library for training\n",
    "import torchmetrics as tm  # For additional metrics\n",
    "# import bitsandbytes as bnb  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9162215",
   "metadata": {
    "papermill": {
     "duration": 0.020168,
     "end_time": "2023-09-26T07:46:50.862230",
     "exception": false,
     "start_time": "2023-09-26T07:46:50.842062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ðŸ“Š Define constants and configuration values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256fb48a",
   "metadata": {
    "papermill": {
     "duration": 0.020888,
     "end_time": "2023-09-26T07:46:50.904373",
     "exception": false,
     "start_time": "2023-09-26T07:46:50.883485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explanation:**\n",
    "\n",
    "```python\n",
    "NODE_OP_CODES = 120\n",
    "```\n",
    "\n",
    "- This line defines a constant variable named `NODE_OP_CODES`.\n",
    "- It assigns the value `120` to the `NODE_OP_CODES` variable.\n",
    "- This variable likely represents the number of node operation codes used in your project.\n",
    "\n",
    "```python\n",
    "NODE_FEATS = 140\n",
    "```\n",
    "\n",
    "- This line defines another constant variable named `NODE_FEATS`.\n",
    "- It assigns the value `140` to the `NODE_FEATS` variable.\n",
    "- This variable likely represents the number of node features used in your project.\n",
    "\n",
    "```python\n",
    "CONFIG_FEATS = 24\n",
    "```\n",
    "\n",
    "- This line defines a constant variable named `CONFIG_FEATS`.\n",
    "- It assigns the value `24` to the `CONFIG_FEATS` variable.\n",
    "- This variable likely represents the number of configuration features used in your project.\n",
    "\n",
    "```python\n",
    "NODE_CONFIG_FEATS = 18\n",
    "```\n",
    "\n",
    "- This line defines a constant variable named `NODE_CONFIG_FEATS`.\n",
    "- It assigns the value `18` to the `NODE_CONFIG_FEATS` variable.\n",
    "- This variable likely represents the number of combined node and configuration features used in your project.\n",
    "\n",
    "These lines of code are used to set specific numeric values that are used as constants or configuration parameters in your project. They provide clarity and allow for easy modification of these values throughout your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8db39d1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:46:50.949141Z",
     "iopub.status.busy": "2023-09-26T07:46:50.948321Z",
     "iopub.status.idle": "2023-09-26T07:46:50.954041Z",
     "shell.execute_reply": "2023-09-26T07:46:50.952945Z"
    },
    "papermill": {
     "duration": 0.032095,
     "end_time": "2023-09-26T07:46:50.956915",
     "exception": false,
     "start_time": "2023-09-26T07:46:50.924820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NODE_OP_CODES = 120  # Number of node operation codes\n",
    "NODE_FEATS = 140     # Number of node features\n",
    "CONFIG_FEATS = 24    # Number of configuration features\n",
    "NODE_CONFIG_FEATS = 18  # Number of combined node and configuration features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0b0c89",
   "metadata": {
    "papermill": {
     "duration": 0.025246,
     "end_time": "2023-09-26T07:46:51.003149",
     "exception": false,
     "start_time": "2023-09-26T07:46:50.977903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " ##  ðŸ“„  Function to Generate Tile DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a2a9a8",
   "metadata": {
    "papermill": {
     "duration": 0.021477,
     "end_time": "2023-09-26T07:46:51.047124",
     "exception": false,
     "start_time": "2023-09-26T07:46:51.025647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explanation:**\n",
    "\n",
    "- `DATA_DIR` is a constant that stores the directory path for the data files.\n",
    "- `generate_tile_df` is a function used to generate a Pandas DataFrame containing information about tiles.\n",
    "- Inside the function:\n",
    "  - A DataFrame called `tile_df` is created with a 'paths' column containing file paths.\n",
    "  - Additional columns are added to `tile_df` using the `.assign` method and lambda functions:\n",
    "    - `split`: Extracts the name of the immediate parent directory.\n",
    "    - `configuration`: Extracts the name of the parent's parent directory.\n",
    "    - `extra`: Extracts the name of the parent's parent's parent directory.\n",
    "    - `model_name`: Extracts the stem (base name without extension) of the file path.\n",
    "    - `collection`: Combines 'extra' and 'configuration' with a ':' separator.\n",
    "    - `ID`: Combines 'collection' and 'model_name' with a ':' separator.\n",
    "    - `paths`: Converts file paths to strings.\n",
    "\n",
    "This function processes file paths and extracts relevant information, organizing it into a DataFrame. It's a useful step for data preprocessing or exploration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04b4add",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:46:51.098819Z",
     "iopub.status.busy": "2023-09-26T07:46:51.098250Z",
     "iopub.status.idle": "2023-09-26T07:46:51.110004Z",
     "shell.execute_reply": "2023-09-26T07:46:51.108594Z"
    },
    "papermill": {
     "duration": 0.042792,
     "end_time": "2023-09-26T07:46:51.112974",
     "exception": false,
     "start_time": "2023-09-26T07:46:51.070182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = \"../input/predict-ai-model-runtime/npz_all/npz\"\n",
    "\n",
    "\n",
    "def generate_tile_df() -> pd.DataFrame:\n",
    "    tile_df = pd.DataFrame({'paths': [elem for elem in (Path(DATA_DIR) / 'tile').rglob(\"*\") if elem.is_file()]}).assign(\n",
    "        split=lambda df: df.paths.apply(lambda x: x.parent.name),\n",
    "        configuration=lambda df: df.paths.apply(lambda x: x.parent.parent.name),\n",
    "        extra=lambda df: df.paths.apply(lambda x: x.parent.parent.parent.name),\n",
    "        model_name=lambda df: df.paths.apply(lambda x: x.stem),\n",
    "        collection=lambda df: df.extra + ':' + df.configuration ,\n",
    "        ID=lambda df: df.collection + ':' + df.model_name ,\n",
    "        paths = lambda df: df.paths.apply(lambda x: str(x))\n",
    "    )\n",
    "    return tile_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd4318",
   "metadata": {
    "papermill": {
     "duration": 0.025084,
     "end_time": "2023-09-26T07:46:51.159373",
     "exception": false,
     "start_time": "2023-09-26T07:46:51.134289",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ðŸ§© Generating and Displaying Tile DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb868e",
   "metadata": {
    "papermill": {
     "duration": 0.021701,
     "end_time": "2023-09-26T07:46:51.227180",
     "exception": false,
     "start_time": "2023-09-26T07:46:51.205479",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explanation:**\n",
    "\n",
    "- In this cell, you are executing the `generate_tile_df` function to create a DataFrame named `tile_df` containing information about tiles.\n",
    "- `tile_df.head()` is used to display the first few rows of the DataFrame, allowing you to inspect the data and its structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35063fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:46:51.374441Z",
     "iopub.status.busy": "2023-09-26T07:46:51.373877Z",
     "iopub.status.idle": "2023-09-26T07:46:59.515690Z",
     "shell.execute_reply": "2023-09-26T07:46:59.513841Z"
    },
    "papermill": {
     "duration": 8.168319,
     "end_time": "2023-09-26T07:46:59.518866",
     "exception": false,
     "start_time": "2023-09-26T07:46:51.350547",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paths</th>\n",
       "      <th>split</th>\n",
       "      <th>configuration</th>\n",
       "      <th>extra</th>\n",
       "      <th>model_name</th>\n",
       "      <th>collection</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../input/predict-ai-model-runtime/npz_all/npz/...</td>\n",
       "      <td>valid</td>\n",
       "      <td>xla</td>\n",
       "      <td>tile</td>\n",
       "      <td>resnet_v1_50_official_batch_128_bf16_2bea628b7...</td>\n",
       "      <td>tile:xla</td>\n",
       "      <td>tile:xla:resnet_v1_50_official_batch_128_bf16_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../input/predict-ai-model-runtime/npz_all/npz/...</td>\n",
       "      <td>valid</td>\n",
       "      <td>xla</td>\n",
       "      <td>tile</td>\n",
       "      <td>inception_v3_batch_128_train_40fa8f86f121f00a</td>\n",
       "      <td>tile:xla</td>\n",
       "      <td>tile:xla:inception_v3_batch_128_train_40fa8f86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../input/predict-ai-model-runtime/npz_all/npz/...</td>\n",
       "      <td>valid</td>\n",
       "      <td>xla</td>\n",
       "      <td>tile</td>\n",
       "      <td>inception_v3_batch_128_train_-23e94c034a65a177</td>\n",
       "      <td>tile:xla</td>\n",
       "      <td>tile:xla:inception_v3_batch_128_train_-23e94c0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../input/predict-ai-model-runtime/npz_all/npz/...</td>\n",
       "      <td>valid</td>\n",
       "      <td>xla</td>\n",
       "      <td>tile</td>\n",
       "      <td>inception_v3_batch_128_train_171f4371caf28639</td>\n",
       "      <td>tile:xla</td>\n",
       "      <td>tile:xla:inception_v3_batch_128_train_171f4371...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../input/predict-ai-model-runtime/npz_all/npz/...</td>\n",
       "      <td>valid</td>\n",
       "      <td>xla</td>\n",
       "      <td>tile</td>\n",
       "      <td>mlperf_bert_batch_24_2x2_-25e30862c042a2b8</td>\n",
       "      <td>tile:xla</td>\n",
       "      <td>tile:xla:mlperf_bert_batch_24_2x2_-25e30862c04...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               paths  split configuration  \\\n",
       "0  ../input/predict-ai-model-runtime/npz_all/npz/...  valid           xla   \n",
       "1  ../input/predict-ai-model-runtime/npz_all/npz/...  valid           xla   \n",
       "2  ../input/predict-ai-model-runtime/npz_all/npz/...  valid           xla   \n",
       "3  ../input/predict-ai-model-runtime/npz_all/npz/...  valid           xla   \n",
       "4  ../input/predict-ai-model-runtime/npz_all/npz/...  valid           xla   \n",
       "\n",
       "  extra                                         model_name collection  \\\n",
       "0  tile  resnet_v1_50_official_batch_128_bf16_2bea628b7...   tile:xla   \n",
       "1  tile      inception_v3_batch_128_train_40fa8f86f121f00a   tile:xla   \n",
       "2  tile     inception_v3_batch_128_train_-23e94c034a65a177   tile:xla   \n",
       "3  tile      inception_v3_batch_128_train_171f4371caf28639   tile:xla   \n",
       "4  tile         mlperf_bert_batch_24_2x2_-25e30862c042a2b8   tile:xla   \n",
       "\n",
       "                                                  ID  \n",
       "0  tile:xla:resnet_v1_50_official_batch_128_bf16_...  \n",
       "1  tile:xla:inception_v3_batch_128_train_40fa8f86...  \n",
       "2  tile:xla:inception_v3_batch_128_train_-23e94c0...  \n",
       "3  tile:xla:inception_v3_batch_128_train_171f4371...  \n",
       "4  tile:xla:mlperf_bert_batch_24_2x2_-25e30862c04...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ðŸ§© Generate the tile DataFrame using the previously defined function\n",
    "tile_df = generate_tile_df()\n",
    "\n",
    "# ðŸ“‹ Display the first few rows of the tile DataFrame\n",
    "tile_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe4b558",
   "metadata": {
    "papermill": {
     "duration": 0.024731,
     "end_time": "2023-09-26T07:46:59.567411",
     "exception": false,
     "start_time": "2023-09-26T07:46:59.542680",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## ðŸ“Š Definition of Functions and a Custom Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2f4640",
   "metadata": {
    "papermill": {
     "duration": 0.025224,
     "end_time": "2023-09-26T07:46:59.618348",
     "exception": false,
     "start_time": "2023-09-26T07:46:59.593124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explanation:**\n",
    "\n",
    "```python\n",
    "\n",
    "def edges_adjacency(edges: torch.Tensor, add_diagonal=True) -> torch.Tensor:\n",
    "   \n",
    "```\n",
    "\n",
    "- This line defines a Python function named `edges_adjacency`.\n",
    "- The function takes two arguments: `edges`, which is expected to be a PyTorch tensor of shape `(num_edges, 2)` representing edges in a graph, and `add_diagonal`, a boolean parameter that indicates whether a diagonal should be added to the adjacency matrix.\n",
    "\n",
    "\n",
    "```python\n",
    "    adjacency_matrix = torch.zeros((edges.max() + 1, edges.max() + 1))\n",
    "```\n",
    "\n",
    "- This line initializes an adjacency matrix (`adjacency_matrix`) as a square matrix of zeros using `torch.zeros`. The matrix dimensions are determined by the maximum value in the `edges` tensor.\n",
    "\n",
    "```python\n",
    "    adjacency_matrix[edges[:, 0], edges[:, 1]] = 1\n",
    "```\n",
    "\n",
    "- Here, the edges are added to the adjacency matrix by setting the corresponding entries to `1`. This creates the connections between nodes in the graph.\n",
    "\n",
    "```python\n",
    "    if add_diagonal:\n",
    "        diag_idx = torch.arange(adjacency_matrix.shape[0])\n",
    "        adjacency_matrix[diag_idx, diag_idx] = 1\n",
    "```\n",
    "\n",
    "- This block of code checks if `add_diagonal` is `True`. If it is, it adds a diagonal to the adjacency matrix. The diagonal represents self-connections of nodes, which is common in some graph representations.\n",
    "\n",
    "```python\n",
    "    return adjacency_matrix\n",
    "```\n",
    "\n",
    "- Finally, the function returns the generated adjacency matrix.\n",
    "\n",
    "In summary, this function takes a list of edges and constructs an adjacency matrix for a graph. It offers the option to include self-connections (diagonal) in the adjacency matrix, which can be useful in various graph-based tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7dead66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:46:59.673987Z",
     "iopub.status.busy": "2023-09-26T07:46:59.672774Z",
     "iopub.status.idle": "2023-09-26T07:46:59.698397Z",
     "shell.execute_reply": "2023-09-26T07:46:59.697125Z"
    },
    "papermill": {
     "duration": 0.05861,
     "end_time": "2023-09-26T07:46:59.702493",
     "exception": false,
     "start_time": "2023-09-26T07:46:59.643883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def edges_adjacency(edges: torch.Tensor, add_diagonal=True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Generate an adjacency matrix from the edges\n",
    "    Args:\n",
    "        edges: Tensor of shape (num_edges, 2) with the edges\n",
    "        add_diagonal: Boolean indicating if the diagonal should be added to the adjacency matrix\n",
    "    Returns:\n",
    "        adjacency_matrix: Tensor of shape (num_nodes, num_nodes) with the adjacency matrix\n",
    "    \"\"\"\n",
    "    adjacency_matrix = torch.zeros((edges.max() + 1, edges.max() + 1))\n",
    "    adjacency_matrix[edges[:, 0], edges[:, 1]] = 1\n",
    "    if add_diagonal:\n",
    "        diag_idx = torch.arange(adjacency_matrix.shape[0])\n",
    "        adjacency_matrix[diag_idx, diag_idx] = 1\n",
    "    return adjacency_matrix\n",
    "\n",
    "def tile_loader(path):\n",
    "    tile_dict =  dict(np.load(path))\n",
    "    tile_dict = {k: torch.from_numpy(v) for k, v in tile_dict.items()}\n",
    "    tile_dict['edges_adjecency'] = edges_adjacency(tile_dict['edge_index'])\n",
    "    return tile_dict\n",
    "\n",
    "def node_cls_token(elem_dict, shift_node_config_ids:bool=True):\n",
    "    \"\"\"\n",
    "    Add a cls token to the node opcode, features, edges adjacency matrix, shift node_config_ids by 1 to account for the cls token\n",
    "    Args:\n",
    "        elem_dict: Dictionary with the elements of the tile\n",
    "    Returns:\n",
    "        elem_dict: Dictionary with the elements of the tile with the cls token\n",
    "    \"\"\"\n",
    "    elem_dict['node_opcode'] = torch.cat([torch.tensor([0]), elem_dict['node_opcode']])\n",
    "    elem_dict['node_feat'] = torch.cat([torch.zeros((1, elem_dict['node_feat'].shape[1])), elem_dict['node_feat']])\n",
    "    elem_dict['edges_adjecency'] = F.pad(elem_dict['edges_adjecency'], (1,0,1,0), value=1)\n",
    "    if 'node_config_ids' in elem_dict and shift_node_config_ids:\n",
    "        elem_dict['node_config_ids'] = elem_dict['node_config_ids'] + 1\n",
    "    return elem_dict\n",
    "\n",
    "\n",
    "class TileDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df:pd.DataFrame ,add_cls_token:bool=True, num_configs:int=10,  max_configs:Optional[int]=None):\n",
    "        self.df = df\n",
    "        self.add_cls_token = add_cls_token\n",
    "        self.num_configs = num_configs\n",
    "        self.max_configs = max_configs  \n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "    \n",
    "    def select_configs(self, total_configs:int):\n",
    "        if self.max_configs is not None:\n",
    "            total_configs = min(total_configs, self.max_configs)\n",
    "        if self.num_configs == -1:\n",
    "            return np.arange(total_configs)\n",
    "        if total_configs < self.num_configs:\n",
    "            return np.random.choice(total_configs, self.num_configs, replace=True)\n",
    "        return  np.random.choice(total_configs, self.num_configs, replace=False)\n",
    "    \n",
    "    def __getitem__(self, idx:int, selected_configs:List[int]=None):\n",
    "        tile_dict = tile_loader(self.df.paths[idx])\n",
    "        if selected_configs is None:\n",
    "            selected_configs = self.select_configs(tile_dict['config_feat'].shape[0])\n",
    "        tile_dict['node_config_feat'] = tile_dict.pop('config_feat')[selected_configs]\n",
    "        tile_dict['node_config_feat'] = F.pad(tile_dict['node_config_feat'].unsqueeze(1), (0,NODE_CONFIG_FEATS))\n",
    "        tile_dict['config_runtime'] = tile_dict['config_runtime'][selected_configs].float()\n",
    "        tile_dict['config_runtime'] /= tile_dict['config_runtime_normalizers'][selected_configs].float()\n",
    "        tile_dict['node_config_ids'] = torch.zeros((1,))\n",
    "        tile_dict['selected_idxs'] = selected_configs\n",
    "        if self.add_cls_token:\n",
    "            tile_dict = node_cls_token(tile_dict, False)\n",
    "        return tile_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0f9ca8",
   "metadata": {
    "papermill": {
     "duration": 0.021243,
     "end_time": "2023-09-26T07:46:59.747690",
     "exception": false,
     "start_time": "2023-09-26T07:46:59.726447",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating a Tile Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f554378",
   "metadata": {
    "papermill": {
     "duration": 0.021216,
     "end_time": "2023-09-26T07:46:59.792587",
     "exception": false,
     "start_time": "2023-09-26T07:46:59.771371",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**\n",
    "\n",
    "\n",
    "```python\n",
    "tile_dataset = TileDataset(tile_df)\n",
    "```\n",
    "\n",
    "- `TileDataset` is a custom dataset class that you defined earlier. It is designed to work with tile data for machine learning tasks.\n",
    "\n",
    "- `tile_df` is a Pandas DataFrame containing information about tiles. This DataFrame likely includes file paths and associated metadata for the tiles.\n",
    "\n",
    "- The code line creates an instance of the `TileDataset` class named `tile_dataset`. This instance will be used to work with the tile data for various machine learning tasks.\n",
    "\n",
    "- When you create the `TileDataset` instance, it will use the `tile_df` DataFrame as its data source. This means that you can use `tile_dataset` to access and process the tile data stored in `tile_df`.\n",
    "\n",
    "This code line prepares your data for training or other tasks by wrapping it in a custom dataset class, which can make it easier to work with the data in a structured and organized way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e216ba75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:46:59.838987Z",
     "iopub.status.busy": "2023-09-26T07:46:59.838390Z",
     "iopub.status.idle": "2023-09-26T07:46:59.845222Z",
     "shell.execute_reply": "2023-09-26T07:46:59.843574Z"
    },
    "papermill": {
     "duration": 0.034325,
     "end_time": "2023-09-26T07:46:59.848928",
     "exception": false,
     "start_time": "2023-09-26T07:46:59.814603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tile_dataset = TileDataset(tile_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43020e6",
   "metadata": {
    "papermill": {
     "duration": 0.022052,
     "end_time": "2023-09-26T07:46:59.893174",
     "exception": false,
     "start_time": "2023-09-26T07:46:59.871122",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Accessing Tile Data from the Dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c55ad56",
   "metadata": {
    "papermill": {
     "duration": 0.022792,
     "end_time": "2023-09-26T07:46:59.938760",
     "exception": false,
     "start_time": "2023-09-26T07:46:59.915968",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**\n",
    "\n",
    "The provided code retrieves and inspects data from the `tile_dataset` created earlier. Let's go through it line by line:\n",
    "\n",
    "```python\n",
    "elem = tile_dataset[0]\n",
    "```\n",
    "\n",
    "- This line retrieves the first element from the `tile_dataset` by indexing it with `[0]`. In Python, when you index a dataset or list with `[0]`, you get the first item in the dataset.\n",
    "\n",
    "- The retrieved element is stored in the variable `elem`. This element likely represents a tile or a sample from your dataset.\n",
    "\n",
    "```python\n",
    "for k, v in elem.items():\n",
    "    print(k, v.shape)\n",
    "```\n",
    "\n",
    "- This block of code iterates through the key-value pairs in the `elem` dictionary, where keys represent different data components, and values are tensors.\n",
    "\n",
    "- For each key-value pair, it prints the key (likely a data component name) and the shape of the corresponding tensor.\n",
    "\n",
    "This code allows you to inspect the structure of the first tile or sample in your dataset by printing the names of different data components and their respective tensor shapes. It's a useful step for understanding the structure of your data and preparing it for further processing or model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72554d68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:46:59.990735Z",
     "iopub.status.busy": "2023-09-26T07:46:59.989715Z",
     "iopub.status.idle": "2023-09-26T07:47:00.154323Z",
     "shell.execute_reply": "2023-09-26T07:47:00.152170Z"
    },
    "papermill": {
     "duration": 0.194736,
     "end_time": "2023-09-26T07:47:00.157840",
     "exception": false,
     "start_time": "2023-09-26T07:46:59.963104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_feat torch.Size([81, 140])\n",
      "node_opcode torch.Size([81])\n",
      "edge_index torch.Size([86, 2])\n",
      "config_runtime torch.Size([10])\n",
      "config_runtime_normalizers torch.Size([3246])\n",
      "edges_adjecency torch.Size([81, 81])\n",
      "node_config_feat torch.Size([10, 1, 42])\n",
      "node_config_ids torch.Size([1])\n",
      "selected_idxs (10,)\n"
     ]
    }
   ],
   "source": [
    "elem = tile_dataset[0]\n",
    "for k,v in elem.items():\n",
    "    print(k, v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b4aee",
   "metadata": {
    "papermill": {
     "duration": 0.021382,
     "end_time": "2023-09-26T07:47:00.201984",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.180602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom Functions for Data Preparation and Collation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4002192e",
   "metadata": {
    "papermill": {
     "duration": 0.022452,
     "end_time": "2023-09-26T07:47:00.249061",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.226609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**\n",
    "\n",
    "```python\n",
    "def pad_edge_adjacency(edges_adjacency_list):\n",
    "    max_len = max([elem.shape[0] for elem in edges_adjacency_list])\n",
    "    return torch.stack([F.pad(elem, (0, max_len-elem.shape[0], 0, max_len-elem.shape[0]), value=0) for elem in edges_adjacency_list], dim=0)\n",
    "```\n",
    "\n",
    "- `pad_edge_adjacency` is a function that takes a list of edge adjacency matrices (`edges_adjacency_list`) and pads them to have the same size.\n",
    "- It calculates the maximum length among the adjacency matrices.\n",
    "- Then, it uses a list comprehension to iterate through the matrices, pad each matrix to the maximum size, and stack them into a tensor along a new dimension (dimension 0).\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class LayoutCollator:\n",
    "    pad_to_multiple_of: int = 64\n",
    "    targets: bool = True\n",
    "    padding_idx: int = 120\n",
    "    node_padding_idx: int = 0\n",
    "```\n",
    "\n",
    "- `LayoutCollator` is a dataclass that defines a collation strategy for preparing batches of data.\n",
    "- It includes several parameters:\n",
    "  - `pad_to_multiple_of`: Specifies the size to which data should be padded (default is 64).\n",
    "  - `targets`: A boolean indicating whether targets are included in the data (default is True).\n",
    "  - `padding_idx`: The index used for padding in the data (default is 120).\n",
    "  - `node_padding_idx`: The index used for padding in node-related data (default is 0).\n",
    "\n",
    "```python\n",
    "def __call__(self, batch):\n",
    "    # Implementation of collation logic\n",
    "    # ...\n",
    "    return output\n",
    "```\n",
    "\n",
    "- The `LayoutCollator` class defines a `__call__` method, which is called when an instance of this class is used as a function.\n",
    "- Inside the `__call__` method, data collation and padding operations are performed based on the parameters specified when creating an instance of `LayoutCollator`.\n",
    "- The processed data is returned as `output`.\n",
    "\n",
    "The purpose of this code is to provide a data collation strategy for creating batches of data, ensuring that the data has consistent dimensions and padding. This is often necessary when working with neural network models that require inputs of the same size within a batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8786d9da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:00.296247Z",
     "iopub.status.busy": "2023-09-26T07:47:00.295612Z",
     "iopub.status.idle": "2023-09-26T07:47:00.318762Z",
     "shell.execute_reply": "2023-09-26T07:47:00.317116Z"
    },
    "papermill": {
     "duration": 0.050638,
     "end_time": "2023-09-26T07:47:00.322228",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.271590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pad_edge_adjacency(edges_adjacency_list):\n",
    "    max_len = max([elem.shape[0] for elem in edges_adjacency_list])\n",
    "    return torch.stack([F.pad(elem, (0, max_len-elem.shape[0], 0, max_len-elem.shape[0]), value=0) for elem in edges_adjacency_list], dim=0)\n",
    "\n",
    "@dataclass\n",
    "class LayoutCollator:\n",
    "    pad_to_multiple_of: int = 64\n",
    "    targets:bool = True\n",
    "    padding_idx:int = 120\n",
    "    node_padding_idx:int = 0\n",
    "    \n",
    "    def __call__(self, batch):\n",
    "        output = {}\n",
    "        max_node_len = max([elem['node_opcode'].shape[0] for elem in batch])\n",
    "        node_pad_amount = self.pad_to_multiple_of - max_node_len % max(self.pad_to_multiple_of, 1)\n",
    "        output['node_opcode'] = F.pad(pad_sequence([elem['node_opcode'] for elem in batch], batch_first=True, padding_value=self.padding_idx),\n",
    "                                      (0, node_pad_amount), value=self.padding_idx).long()\n",
    "        output['node_feat'] = F.pad(pad_sequence([elem['node_feat'] for elem in batch], batch_first=True),\n",
    "                                    (0,0,0, node_pad_amount), value=0)\n",
    "        output['edges_adjecency'] = F.pad(pad_edge_adjacency([elem['edges_adjecency'] for elem in batch]),\n",
    "                                          (0, node_pad_amount, 0, node_pad_amount), value=0)\n",
    "        output['node_attn_mask'] = F.pad(pad_sequence([torch.ones(len(elem['node_opcode'])) for elem in batch], batch_first=True),\n",
    "                                         (0, node_pad_amount), value=0)\n",
    "\n",
    "        max_node_config_len = max([elem['node_config_ids'].shape[0] for elem in batch])\n",
    "        node_config_pad_amount = self.pad_to_multiple_of - max_node_config_len % max(self.pad_to_multiple_of, 1)\n",
    "        output['node_config_ids'] = F.pad(pad_sequence([elem['node_config_ids'] for elem in batch], batch_first=True),\n",
    "                                         (0, node_config_pad_amount), value=0).long()\n",
    "        padded_node_config_feat = pad_sequence([elem['node_config_feat'].permute(1,0,2) for elem in batch], batch_first=True, padding_value=-1)\n",
    "        padded_node_config_feat = F.pad(padded_node_config_feat.permute(0,2,1,3),\n",
    "                                           (0,0,0, node_config_pad_amount,0,0), value=-1)\n",
    "        \n",
    "        output['node_config_feat'] = torch.where(padded_node_config_feat!=-1, padded_node_config_feat, self.node_padding_idx)\n",
    "                                      \n",
    "        output['config_idxs'] = torch.stack([torch.from_numpy(elem['selected_idxs']) for elem in batch])\n",
    "        \n",
    "        if self.targets:\n",
    "            output['config_runtime'] = pad_sequence([elem['config_runtime'].float() for elem in batch], batch_first=True)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b472c1f",
   "metadata": {
    "papermill": {
     "duration": 0.024626,
     "end_time": "2023-09-26T07:47:00.371460",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.346834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Creating a Collate Function Using `LayoutCollator`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e25607",
   "metadata": {
    "papermill": {
     "duration": 0.022446,
     "end_time": "2023-09-26T07:47:00.418315",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.395869",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**\n",
    "\n",
    "\n",
    "```python\n",
    "collate_fn = LayoutCollator(64)\n",
    "```\n",
    "\n",
    "- `LayoutCollator` is the dataclass defined earlier, which is used to define a collation strategy for preparing batches of data.\n",
    "\n",
    "- The code line creates an instance of the `LayoutCollator` class and assigns it to the variable `collate_fn`.\n",
    "\n",
    "- The value `64` is passed as an argument when creating the `LayoutCollator` instance. This value is used as the `pad_to_multiple_of` parameter, which specifies the size to which data should be padded.\n",
    "\n",
    "By creating this instance, you have defined a collation function (`collate_fn`) that can be used with data loaders to prepare batches of data. The collation function ensures that data within a batch is padded and structured consistently, which is often a requirement when training neural network models.\n",
    "\n",
    "You can later use `collate_fn` when creating data loaders to customize how data is processed and collated when loading batches. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ab864a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:00.470904Z",
     "iopub.status.busy": "2023-09-26T07:47:00.470286Z",
     "iopub.status.idle": "2023-09-26T07:47:00.476703Z",
     "shell.execute_reply": "2023-09-26T07:47:00.475168Z"
    },
    "papermill": {
     "duration": 0.037812,
     "end_time": "2023-09-26T07:47:00.479995",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.442183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "collate_fn = LayoutCollator(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797cdd09",
   "metadata": {
    "papermill": {
     "duration": 0.021801,
     "end_time": "2023-09-26T07:47:00.526162",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.504361",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Collating a Batch of Data Using `collate_fn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b53770",
   "metadata": {
    "papermill": {
     "duration": 0.023861,
     "end_time": "2023-09-26T07:47:00.574225",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.550364",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**\n",
    "\n",
    "```python\n",
    "batch = collate_fn([tile_dataset[0], tile_dataset[1]])\n",
    "```\n",
    "\n",
    "- `collate_fn` is the collation function that you previously created using the `LayoutCollator` dataclass. It defines how data should be prepared and padded when creating batches.\n",
    "\n",
    "- `[tile_dataset[0], tile_dataset[1]]` is a list containing two elements from the `tile_dataset`. These two elements represent two samples or tiles.\n",
    "\n",
    "- The `collate_fn` is called with this list of elements, resulting in the collation of these samples into a batch. The `batch` variable holds the collated batch of data.\n",
    "\n",
    "```python\n",
    "for k, v in batch.items():\n",
    "    print(k, v.shape)\n",
    "```\n",
    "\n",
    "- This block of code iterates through the key-value pairs in the `batch` dictionary.\n",
    "\n",
    "- For each key-value pair, it prints the key (which likely represents a data component name) and the shape of the corresponding tensor (the data).\n",
    "\n",
    "In summary, this code demonstrates how to use the `collate_fn` function to collate a batch of data from the `tile_dataset`. The collated batch contains data components such as node opcodes, features, adjacency matrices, and more. The code then inspects the shapes of these components within the batch.\n",
    "\n",
    "This is a crucial step when working with deep learning models that require consistent batch input shapes, as it ensures that the data is appropriately padded and structured for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b82f04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:00.625189Z",
     "iopub.status.busy": "2023-09-26T07:47:00.624651Z",
     "iopub.status.idle": "2023-09-26T07:47:00.664916Z",
     "shell.execute_reply": "2023-09-26T07:47:00.663012Z"
    },
    "papermill": {
     "duration": 0.069343,
     "end_time": "2023-09-26T07:47:00.668450",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.599107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_opcode torch.Size([2, 128])\n",
      "node_feat torch.Size([2, 128, 140])\n",
      "edges_adjecency torch.Size([2, 128, 128])\n",
      "node_attn_mask torch.Size([2, 128])\n",
      "node_config_ids torch.Size([2, 64])\n",
      "node_config_feat torch.Size([2, 10, 64, 42])\n",
      "config_idxs torch.Size([2, 10])\n",
      "config_runtime torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "batch = collate_fn([tile_dataset[0], tile_dataset[1]])\n",
    "for k,v in batch.items():\n",
    "    print(k,v.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d822a14",
   "metadata": {
    "papermill": {
     "duration": 0.023541,
     "end_time": "2023-09-26T07:47:00.714606",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.691065",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Defining`GraphConfig` Dataclass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e487d166",
   "metadata": {
    "papermill": {
     "duration": 0.021874,
     "end_time": "2023-09-26T07:47:00.759852",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.737978",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**\n",
    "\n",
    "- `@dataclass` is a decorator that simplifies the creation of classes for storing data with default values.\n",
    "\n",
    "- The `GraphConfig` class defines various hyperparameters as class attributes, each with a default value. These attributes include the number of hidden layers, hidden size, number of attention heads, intermediate size, dropout probabilities, and other hyperparameters commonly used in neural network models.\n",
    "\n",
    "- The `__post_init__` method is defined to perform post-initialization tasks. In this case, it calculates the `embedding_size` attribute as equal to `hidden_size` by default.\n",
    "\n",
    "- The `validate` method checks if the hidden size is a multiple of the number of attention heads and raises a `ValueError` if it's not. This is a common validation step in models using attention mechanisms.\n",
    "\n",
    "- `save_config` and `load_config` methods are defined to save the configuration to a JSON file and load it from a JSON file, respectively. These methods allow you to save and load model configurations easily.\n",
    "\n",
    "This `GraphConfig` dataclass serves as a convenient way to configure hyperparameters for graph-based models and provides methods for validation and serialization of configurations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af621de8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:00.811939Z",
     "iopub.status.busy": "2023-09-26T07:47:00.811413Z",
     "iopub.status.idle": "2023-09-26T07:47:00.827454Z",
     "shell.execute_reply": "2023-09-26T07:47:00.825858Z"
    },
    "papermill": {
     "duration": 0.045674,
     "end_time": "2023-09-26T07:47:00.830962",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.785288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GraphConfig:\n",
    "    num_hidden_layers: int = 8\n",
    "    hidden_size: int = 256\n",
    "    num_attention_heads: int = 16\n",
    "    intermediate_size: int = 64\n",
    "    chunk_size_feed_forward: int = 64\n",
    "    attention_probs_dropout_prob: float = 0.0\n",
    "    max_position_embeddings: int = 512\n",
    "    hidden_dropout_prob: float = 0.0\n",
    "    layer_norm_eps: float = 1e-12\n",
    "    hidden_act: str = 'gelu'\n",
    "    initializer_range: float = 0.02\n",
    "    output_hidden_states: bool = False\n",
    "    output_attentions: bool = False\n",
    "    gradient_checkpointing: bool = False\n",
    "    margin: float = 0.1\n",
    "    number_permutations: int = 10\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.embedding_size = self.hidden_size\n",
    "    \n",
    "    def validate(self):\n",
    "        if self.hidden_size % self.num_attention_heads != 0 and not hasattr(self, \"embedding_size\"):\n",
    "            raise ValueError(\n",
    "                f\"The hidden size ({self.hidden_size}) is not a multiple of the number of attention \"\n",
    "                f\"heads ({self.num_attention_heads})\"\n",
    "            )\n",
    "            \n",
    "    def save_config(self, path):\n",
    "        config = asdict(self)\n",
    "        with open(path, 'w') as f:\n",
    "            json.dump(config, f)\n",
    "            \n",
    "    @classmethod\n",
    "    def load_config(cls, path):\n",
    "        with open(path, 'r') as f:\n",
    "            config = json.load(f)\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed6c406",
   "metadata": {
    "papermill": {
     "duration": 0.022539,
     "end_time": "2023-09-26T07:47:00.876224",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.853685",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Definition of the `MultiElementRankLoss` Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f930f",
   "metadata": {
    "papermill": {
     "duration": 0.022218,
     "end_time": "2023-09-26T07:47:00.922899",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.900681",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**\n",
    "\n",
    "This cell defines a custom PyTorch module named `MultiElementRankLoss`, which is a loss function used for comparing the model's output with the output of the model with permutations of elements.\n",
    "\n",
    "```python\n",
    "class MultiElementRankLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Loss function that compares the output of the model with the output of the model with a permutation of the elements\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "- This class definition begins with a docstring that briefly describes the purpose of the loss function.\n",
    "\n",
    "```python\n",
    "    def __init__(self, margin: float = 0.0, number_permutations: int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.loss_fn = torch.nn.MarginRankingLoss(margin=margin, reduction='none')\n",
    "        self.number_permutations = number_permutations\n",
    "```\n",
    "\n",
    "- The `MultiElementRankLoss` class has an `__init__` method used for initializing instances of the class.\n",
    "- It takes two arguments:\n",
    "  - `margin`: A margin parameter for the margin ranking loss (default is 0.0).\n",
    "  - `number_permutations`: The number of permutations to consider when calculating the loss (default is 1).\n",
    "- Within the `__init__` method:\n",
    "  - `super().__init__()` initializes the parent class (`nn.Module`).\n",
    "  - `self.loss_fn` is created as an instance of `torch.nn.MarginRankingLoss` with the specified margin and a reduction mode of 'none'.\n",
    "  - `self.number_permutations` is set based on the provided `number_permutations`.\n",
    "\n",
    "```python\n",
    "    def generate_permutation(self, config_attn_mask: torch.Tensor):\n",
    "        # Implementation of permutation generation logic\n",
    "        # ...\n",
    "        return permutation\n",
    "```\n",
    "\n",
    "- The `generate_permutation` method generates a permutation of the elements in the batch based on a provided attention mask. It calculates the number of elements in each sequence, generates random permutations, and returns the resulting permutation tensor.\n",
    "\n",
    "```python\n",
    "    def permute_tensor(self, tensor: torch.Tensor, permutation: torch.Tensor, x: torch.Tensor, y: torch.Tensor):\n",
    "        # Implementation of tensor permutation logic\n",
    "        # ...\n",
    "        return permuted_tensor\n",
    "```\n",
    "\n",
    "- The `permute_tensor` method takes a tensor, a permutation tensor, and coordinates for elements to be permuted. It creates a new tensor with elements permuted according to the provided permutation.\n",
    "\n",
    "```python\n",
    "    def calculate_rank_loss(self, outputs: torch.Tensor, config_runtime: torch.Tensor, config_idxs: torch.Tensor):\n",
    "        # Implementation of rank loss calculation logic\n",
    "        # ...\n",
    "        return loss\n",
    "```\n",
    "\n",
    "- The `calculate_rank_loss` method calculates a rank loss by generating a permutation of predictions and targets and comparing them using the margin ranking loss. The result is a loss tensor.\n",
    "\n",
    "```python\n",
    "    def forward(self, outputs: torch.Tensor, config_runtime: torch.Tensor, config_idxs: torch.Tensor):\n",
    "        loss = 0\n",
    "        for _ in range(self.number_permutations):\n",
    "            loss += self.calculate_rank_loss(outputs, config_runtime, config_idxs)\n",
    "        return loss / self.number_permutations\n",
    "```\n",
    "\n",
    "- The `forward` method is the main entry point of the module. It computes the loss by accumulating the rank loss for multiple permutations (controlled by `self.number_permutations`) and then returns the averaged loss.\n",
    "\n",
    "This custom loss function, `MultiElementRankLoss`, is designed for tasks where the model's output needs to be compared with permutations of elements,  for ranking purposes. It provides flexibility in terms of the margin parameter and the number of permutations considered when computing the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a56c40c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:00.970668Z",
     "iopub.status.busy": "2023-09-26T07:47:00.969560Z",
     "iopub.status.idle": "2023-09-26T07:47:00.990895Z",
     "shell.execute_reply": "2023-09-26T07:47:00.989111Z"
    },
    "papermill": {
     "duration": 0.050048,
     "end_time": "2023-09-26T07:47:00.995207",
     "exception": false,
     "start_time": "2023-09-26T07:47:00.945159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiElementRankLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Loss function that compares the output of the model with the output of the model with a permutation of the elements\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, margin:float=0.0, number_permutations:int = 1) -> None:\n",
    "        super().__init__()\n",
    "        self.loss_fn = torch.nn.MarginRankingLoss(margin=margin, reduction = 'none')\n",
    "        self.number_permutations = number_permutations\n",
    "        \n",
    "    def generate_permutation(self,\n",
    "                             config_attn_mask: torch.Tensor\n",
    "                             ):\n",
    "        \"\"\"\n",
    "        Generate a permutation of the elements in the batch\n",
    "        Args:\n",
    "            config_attn_mask: Tensor of shape (bs, seq_len) with 1 in the positions of the elements\n",
    "            and 0 in the positions of the padding\n",
    "        Returns:\n",
    "            permutation: Tensor of shape (2, bs*seq_len) with the permutation of the elements\n",
    "        \"\"\"\n",
    "        num_elements = config_attn_mask.sum(1)\n",
    "        permutation_list = [torch.randperm(int(elem)) for elem in  num_elements.cpu().numpy()]\n",
    "        idxs_list = [num*torch.ones_like(elem) for num, elem in enumerate(permutation_list)]\n",
    "        permutation = torch.stack([torch.cat(idxs_list), torch.cat(permutation_list)])\n",
    "        return permutation\n",
    "    \n",
    "    def permute_tensor(self,\n",
    "                       tensor:torch.Tensor,\n",
    "                       permutation:torch.Tensor,\n",
    "                       x:torch.Tensor,\n",
    "                       y:torch.Tensor\n",
    "                       ):\n",
    "        \"\"\"\n",
    "        Permute the tensor according to the permutation\n",
    "        Args:\n",
    "            tensor: Tensor of shape (bs, seq_len) to be permuted\n",
    "            permutation: Tensor of shape (2, bs*seq_len) with the permutation of the elements\n",
    "            x: Tensor of shape (bs*seq_len) with the x coordinates of the elements to be permuted\n",
    "            y: Tensor of shape (bs*seq_len) with the y coordinates of the elements to be permuted\n",
    "        Returns:\n",
    "            permuted_tensor: Tensor of shape (bs, seq_len) with the permuted elements\n",
    "        \"\"\"\n",
    "        new_tensor = tensor.clone()\n",
    "        new_tensor[x, y] = new_tensor[permutation[0, :], permutation[1, :]]\n",
    "        return new_tensor\n",
    "    \n",
    "    def calculate_rank_loss(self,\n",
    "                            outputs: torch.Tensor,\n",
    "                            config_runtime: torch.Tensor,\n",
    "                            config_idxs: torch.Tensor\n",
    "                            ):\n",
    "        \"\"\"\n",
    "        Generates a permutation of the predictions and targets and calculates the loss MarginRankingLoss against the permutation\n",
    "        Args:\n",
    "            outputs: Tensor of shape (bs, seq_len) with the outputs of the model\n",
    "            config_runtime: Tensor of shape (bs, seq_len) with the runtime of the model\n",
    "            config_mask: Tensor of shape (bs, seq_len) with 1 in the positions of the elements\n",
    "            and 0 in the positions of the padding\n",
    "        Returns:\n",
    "            loss: Tensor of shape (bs, seq_len) with the loss for each element in the batch\n",
    "        \"\"\"\n",
    "        bs, num_configs = outputs.shape\n",
    "        permutation = torch.randperm(num_configs) \n",
    "        permuted_idxs = config_idxs[:, permutation]\n",
    "        config_mask = torch.where(config_idxs != permuted_idxs, 1, 0)\n",
    "        permuted_runtime = config_runtime[:, permutation]\n",
    "        labels = 2*((config_runtime - permuted_runtime) > 0) -1\n",
    "        permuted_output = outputs[:, permutation]\n",
    "        loss = self.loss_fn(outputs.view(-1,1), permuted_output.view(-1,1), labels.view(-1,1))\n",
    "        loss = loss.view(bs, num_configs) * config_mask\n",
    "        return loss.mean()\n",
    "                \n",
    "    \n",
    "    def forward(self,\n",
    "                outputs: torch.Tensor,\n",
    "                config_runtime: torch.Tensor,\n",
    "                config_idxs: torch.Tensor\n",
    "                ):\n",
    "        loss = 0 \n",
    "        for _ in range(self.number_permutations):\n",
    "            loss += self.calculate_rank_loss(outputs, config_runtime, config_idxs)\n",
    "        return loss/ self.number_permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79aeaf6e",
   "metadata": {
    "papermill": {
     "duration": 0.022109,
     "end_time": "2023-09-26T07:47:01.040045",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.017936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Definition of the `TileTopK` Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ede7a",
   "metadata": {
    "papermill": {
     "duration": 0.021454,
     "end_time": "2023-09-26T07:47:01.083544",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.062090",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**\n",
    "\n",
    "This cell defines a custom metric named `TileTopK` that extends the `torchmetrics.Metric` class. This metric is designed to measure the performance of a model in a top-k ranking task for tile runtimes.\n",
    "\n",
    "```python\n",
    "class TileTopK(tm.Metric):\n",
    "    \n",
    "    higher_is_better = True\n",
    "```\n",
    "\n",
    "- `TileTopK` is defined as a subclass of `torchmetrics.Metric`. It's important to note that the `higher_is_better` attribute is set to `True`, indicating that higher values of this metric are considered better.\n",
    "\n",
    "```python\n",
    "    def __init__(self, k: int = 5) -> None:\n",
    "        super().__init__()\n",
    "        self.add_state(\"runtimes\", default=[], dist_reduce_fx=None)\n",
    "        self.k = k\n",
    "```\n",
    "\n",
    "- The `__init__` method initializes instances of the `TileTopK` metric. It takes one argument, `k`, which specifies the value of k for the top-k ranking.\n",
    "- Inside the method:\n",
    "  - `super().__init__()` initializes the parent class (`torchmetrics.Metric`).\n",
    "  - `self.add_state(\"runtimes\", default=[], dist_reduce_fx=None)` defines a state variable named \"runtimes\" to store metric values. This variable starts as an empty list and does not perform any distributed reduction.\n",
    "  - `self.k` is set based on the provided `k` argument.\n",
    "\n",
    "```python\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor, config_attn_mask: torch.Tensor) -> None:\n",
    "        # Implementation of metric state update logic\n",
    "        # ...\n",
    "```\n",
    "\n",
    "- The `update` method updates the metric state based on predicted values (`preds`), target values (`target`), and an attention mask (`config_attn_mask`).\n",
    "- Within this method, the following logic is implemented:\n",
    "  - It computes the best runtimes from the target values using the attention mask.\n",
    "  - It masks the predicted values according to the attention mask and computes the indices of the bottom-k predictions.\n",
    "  - It constructs `bottom_k_positions` to access the predicted runtimes corresponding to the bottom-k predictions.\n",
    "  - It calculates the best predicted runtimes based on `bottom_k_positions`.\n",
    "  - The results are appended to the \"runtimes\" state variable.\n",
    "\n",
    "```python\n",
    "    def compute(self) -> torch.Tensor:\n",
    "        # Implementation of metric computation logic\n",
    "        # ...\n",
    "```\n",
    "\n",
    "- The `compute` method calculates the final metric value based on the updated state.\n",
    "- In this case, it computes the TileTopK metric value, which involves calculating the mean of a specific computation involving runtimes.\n",
    "\n",
    "The `TileTopK` metric is designed to assess the model's performance in ranking tile runtimes using a top-k approach. It maintains a state variable to accumulate values during updates and computes the final metric value when requested.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57d1a673",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:01.129911Z",
     "iopub.status.busy": "2023-09-26T07:47:01.129303Z",
     "iopub.status.idle": "2023-09-26T07:47:01.143371Z",
     "shell.execute_reply": "2023-09-26T07:47:01.141650Z"
    },
    "papermill": {
     "duration": 0.040869,
     "end_time": "2023-09-26T07:47:01.146665",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.105796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class TileTopK(tm.Metric):\n",
    "    \n",
    "    higher_is_better = True\n",
    "    \n",
    "    def __init__(self, k:int=5) -> None:\n",
    "        super().__init__()\n",
    "        self.add_state(\"runtimes\", default=[], dist_reduce_fx=None)\n",
    "        self.k = k\n",
    "        \n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor, config_attn_mask:torch.Tensor) -> None:\n",
    "        \"\"\"\n",
    "        Update the metric state\n",
    "        Args:\n",
    "            preds: Tensor of shape (bs, seq_len) with the predicted runtimes orders\n",
    "            target: Tensor of shape (bs, seq_len) with the target runtimes\n",
    "            config_attn_mask: Tensor of shape (bs, seq_len) with 1 in the positions of the elements\n",
    "        \"\"\"\n",
    "        best_runtimes = torch.where(config_attn_mask==1, target, torch.tensor(float('inf'))).min(1).values\n",
    "        masked_preds = torch.where(config_attn_mask==1, preds, torch.tensor(float('inf')))\n",
    "        pred_bottomk_indices = torch.topk(masked_preds, k=self.k, largest=False).indices\n",
    "        bs = preds.shape[0]\n",
    "        bottom_k_positions = torch.stack([torch.arange(bs).repeat_interleave(self.k).to(config_attn_mask.device), pred_bottomk_indices.view(-1)])\n",
    "        predicted_runtimes = target[bottom_k_positions[0], bottom_k_positions[1]].view(bs,self.k)\n",
    "        best_predicted_runtimes = predicted_runtimes.min(1).values\n",
    "        self.runtimes.append(best_predicted_runtimes/ best_runtimes)\n",
    "        \n",
    "    def compute(self) -> torch.Tensor:\n",
    "        return (2-torch.cat(self.runtimes)).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca6162b",
   "metadata": {
    "papermill": {
     "duration": 0.026295,
     "end_time": "2023-09-26T07:47:01.194549",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.168254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ec704",
   "metadata": {
    "papermill": {
     "duration": 0.030306,
     "end_time": "2023-09-26T07:47:01.256983",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.226677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**:\n",
    "The code defines a neural network model for graph encoding and ranking. \n",
    "\n",
    "1. **BertEncoder**: This class is a part of the BERT-based architecture used for graph encoding. It is responsible for stacking multiple BertLayer instances. It can handle optional output attentions and hidden states.\n",
    "\n",
    "2. **BertLayer**: This class represents a single layer within the BertEncoder. It consists of BertAttention, BertIntermediate, and BertOutput components. Each layer processes the input sequentially through these components.\n",
    "\n",
    "3. **BertIntermediate**: This class takes the output of the attention layer and applies a linear transformation followed by an activation function (e.g., GELU).\n",
    "\n",
    "4. **BertOutput**: This class further processes the intermediate output, applying linear transformation, dropout, and layer normalization.\n",
    "\n",
    "5. **BertAttention**: This class implements the self-attention mechanism. It includes the query, key, and value transformations, computes attention scores, applies dropout, and outputs context vectors.\n",
    "\n",
    "6. **BertSelfAttention**: This class handles the core self-attention computation, including query, key, and value transformations. It also deals with positional embeddings for relative attention, if enabled.\n",
    "\n",
    "7. **BertSelfOutput**: This class takes the attention output and applies linear transformation, dropout, and layer normalization.\n",
    "\n",
    "8. **NodeEncoder**: This class is responsible for encoding node information. It takes node opcodes and features as input, processes them, and applies layer normalization.\n",
    "\n",
    "9. **BertNodeEncoder**: This class combines node embeddings and node encoder layers for encoding node-level information in a BERT-like fashion. It also handles the masking of edges and self-attention.\n",
    "\n",
    "10. **transform_node_positional_embeddings**: This function reshapes node embeddings based on node_config_ids and num_nodes.\n",
    "\n",
    "11. **NodeFeatEmbeddings**: This class is responsible for embedding node configuration features, including positional embeddings.\n",
    "\n",
    "12. **BertGraphEncoder**: This class combines node and node configuration embeddings, applies layer normalization, and passes the data through a BERT-like encoder.\n",
    "\n",
    "13. **GraphEncoder**: This class represents the overall graph encoding model. It uses the BertGraphEncoder to encode graph information and generates output scores. Optionally, it computes a ranking loss based on runtime data.\n",
    "\n",
    "This code defines a complex neural network model for encoding graph data, specifically tailored for the task of ranking elements. It combines BERT-like layers with custom components for encoding both nodes and node configurations, considering self-attention and positional embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27734f2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:01.316177Z",
     "iopub.status.busy": "2023-09-26T07:47:01.315256Z",
     "iopub.status.idle": "2023-09-26T07:47:01.403315Z",
     "shell.execute_reply": "2023-09-26T07:47:01.402041Z"
    },
    "papermill": {
     "duration": 0.119631,
     "end_time": "2023-09-26T07:47:01.406628",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.286997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modified from https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py\n",
    "class BertEncoder(nn.Module):\n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.layer = nn.ModuleList([BertLayer(config) for _ in range(config.num_hidden_layers)])\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "        output_hidden_states: Optional[bool] = False,\n",
    "        return_dict: Optional[bool] = True,\n",
    "    ) -> Union[Tuple[torch.Tensor], BaseModelOutputWithPastAndCrossAttentions]:\n",
    "        all_hidden_states = () if output_hidden_states else None\n",
    "        all_self_attentions = () if output_attentions else None\n",
    "\n",
    "        for i, layer_module in enumerate(self.layer):\n",
    "            if output_hidden_states:\n",
    "                all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "            layer_head_mask = head_mask #DONE: Same Head Mask for all layers\n",
    "\n",
    "            if self.gradient_checkpointing and self.training:\n",
    "\n",
    "                def create_custom_forward(module):\n",
    "                    def custom_forward(*inputs):\n",
    "                        return module(*inputs,  output_attentions)\n",
    "\n",
    "                    return custom_forward\n",
    "\n",
    "                layer_outputs = torch.utils.checkpoint.checkpoint(\n",
    "                    create_custom_forward(layer_module),\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                )\n",
    "            else:\n",
    "                layer_outputs = layer_module(\n",
    "                    hidden_states,\n",
    "                    attention_mask,\n",
    "                    layer_head_mask,\n",
    "                    output_attentions,\n",
    "                )\n",
    "\n",
    "            hidden_states = layer_outputs[0]\n",
    "            if output_attentions:\n",
    "                all_self_attentions = all_self_attentions + (layer_outputs[1],)\n",
    "\n",
    "        if output_hidden_states:\n",
    "            all_hidden_states = all_hidden_states + (hidden_states,)\n",
    "\n",
    "        if not return_dict:\n",
    "            return tuple(\n",
    "                v\n",
    "                for v in [\n",
    "                    hidden_states,\n",
    "                    all_hidden_states,\n",
    "                    all_self_attentions,\n",
    "                ]\n",
    "                if v is not None\n",
    "            )\n",
    "        return BaseModelOutputWithPastAndCrossAttentions(\n",
    "            last_hidden_state=hidden_states,\n",
    "            past_key_values=None,\n",
    "            hidden_states=all_hidden_states,\n",
    "            attentions=all_self_attentions,\n",
    "            cross_attentions=None,\n",
    "        )\n",
    "        \n",
    "        \n",
    "class BertLayer(nn.Module):\n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.chunk_size_feed_forward = config.chunk_size_feed_forward\n",
    "        self.seq_len_dim = 1\n",
    "        self.attention = BertAttention(config)\n",
    "        self.intermediate = BertIntermediate(config)\n",
    "        self.output = BertOutput(config)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        # decoder uni-directional self-attention cached key/values tuple is at positions 1,2\n",
    "        self_attention_outputs = self.attention(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            output_attentions=output_attentions,\n",
    "        )\n",
    "        attention_output = self_attention_outputs[0]\n",
    "        outputs = self_attention_outputs[1:]  # add self attentions if we output attention weights\n",
    "        layer_output = apply_chunking_to_forward(\n",
    "            self.feed_forward_chunk, self.chunk_size_feed_forward, self.seq_len_dim, attention_output\n",
    "        )\n",
    "        outputs = (layer_output,) + outputs\n",
    "\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def feed_forward_chunk(self, attention_output):\n",
    "        intermediate_output = self.intermediate(attention_output)\n",
    "        layer_output = self.output(intermediate_output, attention_output)\n",
    "        return layer_output\n",
    "    \n",
    "class BertIntermediate(nn.Module):\n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.intermediate_size)\n",
    "        if isinstance(config.hidden_act, str):\n",
    "            self.intermediate_act_fn = ACT2FN[config.hidden_act]\n",
    "        else:\n",
    "            self.intermediate_act_fn = config.hidden_act\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.intermediate_act_fn(hidden_states)\n",
    "        return hidden_states\n",
    "    \n",
    "class BertOutput(nn.Module):\n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.intermediate_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "    \n",
    "class BertAttention(nn.Module):\n",
    "    def __init__(self, config:GraphConfig, position_embedding_type=None):\n",
    "        super().__init__()\n",
    "        self.self = BertSelfAttention(config, position_embedding_type=position_embedding_type)\n",
    "        self.output = BertSelfOutput(config)\n",
    "        self.pruned_heads = set()\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        self_outputs = self.self(\n",
    "            hidden_states,\n",
    "            attention_mask,\n",
    "            head_mask,\n",
    "            output_attentions,\n",
    "        )\n",
    "        attention_output = self.output(self_outputs[0], hidden_states)\n",
    "        outputs = (attention_output,) + self_outputs[1:]  # add attentions if we output them\n",
    "        return outputs\n",
    "    \n",
    "    \n",
    "class BertSelfAttention(nn.Module):\n",
    "    def __init__(self, config:GraphConfig, position_embedding_type=None):\n",
    "        super().__init__()\n",
    "        if config.hidden_size % config.num_attention_heads != 0 and not hasattr(config, \"embedding_size\"):\n",
    "            raise ValueError(\n",
    "                f\"The hidden size ({config.hidden_size}) is not a multiple of the number of attention \"\n",
    "                f\"heads ({config.num_attention_heads})\"\n",
    "            )\n",
    "\n",
    "        self.num_attention_heads = config.num_attention_heads\n",
    "        self.attention_head_size = int(config.hidden_size / config.num_attention_heads)\n",
    "        self.all_head_size = self.num_attention_heads * self.attention_head_size\n",
    "\n",
    "        self.query = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.key = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "        self.value = nn.Linear(config.hidden_size, self.all_head_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(config.attention_probs_dropout_prob)\n",
    "        self.position_embedding_type = position_embedding_type or getattr(\n",
    "            config, \"position_embedding_type\", \"absolute\"\n",
    "        )\n",
    "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "            self.max_position_embeddings = config.max_position_embeddings\n",
    "            self.distance_embedding = nn.Embedding(2 * config.max_position_embeddings - 1, self.attention_head_size)\n",
    "\n",
    "\n",
    "    def transpose_for_scores(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        new_x_shape = x.size()[:-1] + (self.num_attention_heads, self.attention_head_size)\n",
    "        x = x.view(new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        output_attentions: Optional[bool] = False,\n",
    "    ) -> Tuple[torch.Tensor]:\n",
    "        mixed_query_layer = self.query(hidden_states)\n",
    "\n",
    "        # If this is instantiated as a cross-attention module, the keys\n",
    "        # and values come from an encoder; the attention mask needs to be\n",
    "        # such that the encoder's padding tokens are not attended to.\n",
    "\n",
    "        key_layer = self.transpose_for_scores(self.key(hidden_states))\n",
    "        value_layer = self.transpose_for_scores(self.value(hidden_states))\n",
    "        query_layer = self.transpose_for_scores(mixed_query_layer)\n",
    "\n",
    "\n",
    "        # Take the dot product between \"query\" and \"key\" to get the raw attention scores.\n",
    "        attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n",
    "\n",
    "        if self.position_embedding_type == \"relative_key\" or self.position_embedding_type == \"relative_key_query\":\n",
    "            query_length, key_length = query_layer.shape[2], key_layer.shape[2]\n",
    "            position_ids_l = torch.arange(query_length, dtype=torch.long, device=hidden_states.device).view(-1, 1)\n",
    "            position_ids_r = torch.arange(key_length, dtype=torch.long, device=hidden_states.device).view(1, -1)\n",
    "            distance = position_ids_l - position_ids_r\n",
    "\n",
    "            positional_embedding = self.distance_embedding(distance + self.max_position_embeddings - 1)\n",
    "            positional_embedding = positional_embedding.to(dtype=query_layer.dtype)  # fp16 compatibility\n",
    "\n",
    "            if self.position_embedding_type == \"relative_key\":\n",
    "                relative_position_scores = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
    "                attention_scores = attention_scores + relative_position_scores\n",
    "            elif self.position_embedding_type == \"relative_key_query\":\n",
    "                relative_position_scores_query = torch.einsum(\"bhld,lrd->bhlr\", query_layer, positional_embedding)\n",
    "                relative_position_scores_key = torch.einsum(\"bhrd,lrd->bhlr\", key_layer, positional_embedding)\n",
    "                attention_scores = attention_scores + relative_position_scores_query + relative_position_scores_key\n",
    "\n",
    "        attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
    "        if attention_mask is not None:\n",
    "            # Apply the attention mask is (precomputed for all layers in BertModel forward() function)\n",
    "            attention_scores = attention_scores + attention_mask\n",
    "\n",
    "        # Normalize the attention scores to probabilities.\n",
    "        attention_probs = nn.functional.softmax(attention_scores, dim=-1)\n",
    "\n",
    "        # This is actually dropping out entire tokens to attend to, which might\n",
    "        # seem a bit unusual, but is taken from the original Transformer paper.\n",
    "        attention_probs = self.dropout(attention_probs)\n",
    "\n",
    "        # Mask heads if we want to\n",
    "        if head_mask is not None:\n",
    "            attention_probs = attention_probs * head_mask #DONE: Same Head Mask for all Heads\n",
    "\n",
    "        context_layer = torch.matmul(attention_probs, value_layer)\n",
    "\n",
    "        context_layer = context_layer.permute(0, 2, 1, 3).contiguous()\n",
    "        new_context_layer_shape = context_layer.size()[:-2] + (self.all_head_size,)\n",
    "        context_layer = context_layer.view(new_context_layer_shape)\n",
    "\n",
    "        outputs = (context_layer, attention_probs) if output_attentions else (context_layer,)\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "class BertSelfOutput(nn.Module):\n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "        self.LayerNorm = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_eps)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "\n",
    "    def forward(self, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n",
    "        hidden_states = self.dense(hidden_states)\n",
    "        hidden_states = self.dropout(hidden_states)\n",
    "        hidden_states = self.LayerNorm(hidden_states + input_tensor)\n",
    "        return hidden_states\n",
    "    \n",
    "    \n",
    "class NodeEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.node_opcode_embeddings = nn.Embedding(NODE_OP_CODES+1 , config.embedding_size, padding_idx=NODE_OP_CODES)\n",
    "        self.linear = nn.Linear(NODE_FEATS, config.embedding_size, bias=False)\n",
    "        self.layer_norm = nn.LayerNorm(config.embedding_size, eps=config.layer_norm_eps)\n",
    "        \n",
    "        \n",
    "    def forward(self,\n",
    "                node_opcode: torch.Tensor,\n",
    "                node_feat: torch.Tensor\n",
    "                ) -> torch.Tensor:\n",
    "        opcode_embeddings = self.node_opcode_embeddings(node_opcode) \n",
    "        node_feats =  self.linear(node_feat)\n",
    "        features = opcode_embeddings + node_feats\n",
    "        features = self.layer_norm(features)\n",
    "        return features\n",
    "    \n",
    "    \n",
    "class BertNodeEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, config:GraphConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.node_embeddings = NodeEncoder(config)\n",
    "        self.node_encoder = BertEncoder(config)\n",
    "        \n",
    "    def forward(self,\n",
    "                node_opcode: torch.Tensor,\n",
    "                node_feat: torch.Tensor,\n",
    "                edges_adjecency: torch.Tensor,\n",
    "                node_attn_mask: torch.Tensor\n",
    "                ):\n",
    "        node_embeddings = self.node_embeddings(node_opcode, node_feat)\n",
    "        node_attn_mask = node_attn_mask.unsqueeze(1).unsqueeze(-1)\n",
    "        node_encoder_outputs = self.node_encoder(node_embeddings,\n",
    "                                                 attention_mask=node_attn_mask,\n",
    "                                                 head_mask=edges_adjecency.unsqueeze(0).repeat(self.config.num_hidden_layers, 1, 1, 1).unsqueeze(2),\n",
    "                                                 output_attentions=True)\n",
    "        return node_encoder_outputs\n",
    "    \n",
    "def transform_node_positional_embeddings(embeddings_output:torch.Tensor,\n",
    "                                         node_config_ids:torch.Tensor,\n",
    "                                         num_nodes:int\n",
    "                                         ) -> torch.Tensor:\n",
    "    bs, num_configs, _, dim = embeddings_output.shape\n",
    "    idxs = node_config_ids.unsqueeze(1).repeat(1,num_configs,1)\n",
    "    zeros = torch.zeros(bs, num_configs, num_nodes, dim, device=embeddings_output.device, dtype=embeddings_output.dtype)\n",
    "    idxs = idxs.unsqueeze(-1).repeat(1,1,1,dim)\n",
    "    zeros.scatter_reduce_(2, idxs, embeddings_output, reduce='sum')\n",
    "    return zeros\n",
    "\n",
    "class NodeFeatEmbeddings(nn.Module):\n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.node_feat_embeddings = nn.Linear(NODE_CONFIG_FEATS + CONFIG_FEATS, config.embedding_size, bias=False)\n",
    "        self.layer_norm = nn.LayerNorm(config.embedding_size, eps=config.layer_norm_eps)\n",
    "        \n",
    "    def forward(self, node_config_feat: torch.Tensor, node_config_ids: torch.Tensor, num_nodes:int) -> torch.Tensor:\n",
    "        node_config_feat_embeddings = self.node_feat_embeddings(node_config_feat)\n",
    "        node_config_feat_embeddings = self.layer_norm(node_config_feat_embeddings)\n",
    "        node_config_feat_embeddings = transform_node_positional_embeddings(node_config_feat_embeddings, node_config_ids, num_nodes)\n",
    "        return node_config_feat_embeddings\n",
    "        \n",
    "    \n",
    "class BertGraphEncoder(nn.Module):\n",
    "    def __init__(self, config:GraphConfig) -> None:\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.node_embeddings = NodeEncoder(config)\n",
    "        self.node_encoder = BertEncoder(config)\n",
    "        self.node_feat_embeddings = NodeFeatEmbeddings(config)\n",
    "        \n",
    "    def forward(self,\n",
    "                node_opcode: torch.Tensor, # (bs, num_nodes)\n",
    "                node_feat: torch.Tensor, # (bs, num_nodes, num_node_feats)\n",
    "                edges_adjecency: torch.Tensor, # (bs, num_nodes, num_nodes)\n",
    "                node_attn_mask: torch.Tensor, # (bs, num_nodes)\n",
    "                node_config_feat: torch.Tensor, # (bs, num_configs, num_config_nodes, num_node_feats)\n",
    "                node_config_ids: torch.Tensor, # (bs, num_configs, num_config_nodes)\n",
    "                ):\n",
    "        bs, num_nodes = node_opcode.shape\n",
    "        num_configs = node_config_feat.shape[1]\n",
    "        node_embeddings = self.node_embeddings(node_opcode, node_feat)\n",
    "        node_config_feat_embeddings = self.node_feat_embeddings(node_config_feat, node_config_ids, num_nodes)\n",
    "        \n",
    "        node_embeddings = node_embeddings.unsqueeze(1).repeat(1, num_configs, 1, 1)\n",
    "        node_embeddings += node_config_feat_embeddings\n",
    "        node_attn_mask = node_attn_mask.unsqueeze(1).repeat(1, num_configs, 1)\n",
    "        node_embeddings = node_embeddings.reshape(bs *num_configs, num_nodes, -1)\n",
    "        node_attn_mask = node_attn_mask.reshape(bs *num_configs, num_nodes)\n",
    "        node_attn_mask = node_attn_mask.unsqueeze(1).unsqueeze(-1)\n",
    "        edges_adjecency = edges_adjecency.unsqueeze(1).repeat(1, num_configs, 1, 1).reshape(bs *num_configs, num_nodes, num_nodes)\n",
    "        edges_adjecency = edges_adjecency.unsqueeze(1)\n",
    "        \n",
    "\n",
    "        node_encoder_outputs = self.node_encoder(node_embeddings,\n",
    "                                                 attention_mask=node_attn_mask,\n",
    "                                                 # head_mask=edges_adjecency.unsqueeze(0).repeat(self.config.num_hidden_layers, 1, 1, 1).unsqueeze(2),\n",
    "                                                 head_mask=edges_adjecency,\n",
    "                                                 output_attentions=True)\n",
    "        \n",
    "        return node_encoder_outputs.last_hidden_state.reshape(bs, num_configs, num_nodes, -1)\n",
    "    \n",
    "    \n",
    "class GraphEncoder(nn.Module):\n",
    "    \n",
    "    config_class = GraphConfig\n",
    "    \n",
    "    def __init__(self, config:GraphConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.node_encoder = BertGraphEncoder(config)\n",
    "        self.head = nn.Linear(config.hidden_size, 1)\n",
    "        self.loss_fn = MultiElementRankLoss(margin=config.margin, number_permutations=config.number_permutations)\n",
    "        \n",
    "        \n",
    "    def forward(self,\n",
    "                node_opcode: torch.Tensor, # (bs, num_nodes)\n",
    "                node_feat: torch.Tensor, # (bs, num_nodes, num_node_feats)\n",
    "                edges_adjecency: torch.Tensor, # (bs, num_nodes, num_nodes)\n",
    "                node_attn_mask: torch.Tensor, # (bs, num_nodes)\n",
    "                node_config_feat: torch.Tensor, # (bs, num_configs, num_config_nodes, num_node_feats)\n",
    "                node_config_ids: torch.Tensor, # (bs, num_configs, num_config_nodes)\n",
    "                config_idxs: Optional[torch.Tensor] = None, # (bs, num_configs)\n",
    "                config_runtime: Optional[torch.Tensor] = None,):\n",
    "        \n",
    "        last_hidden_state = self.node_encoder(node_opcode,\n",
    "                                    node_feat,\n",
    "                                    edges_adjecency,\n",
    "                                    node_attn_mask,\n",
    "                                    node_config_feat,\n",
    "                                    node_config_ids)\n",
    "        \n",
    "        output = self.head(last_hidden_state[:,:,0]).squeeze(-1)\n",
    "        outputs = {'outputs': output, 'order': torch.argsort(output, dim=1)}\n",
    "        if config_runtime is not None:\n",
    "            loss = 0\n",
    "            loss += self.loss_fn(output, config_runtime, config_idxs)\n",
    "            outputs['loss'] = loss\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77492a22",
   "metadata": {
    "papermill": {
     "duration": 0.021207,
     "end_time": "2023-09-26T07:47:01.450165",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.428958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  `LightningWrapper` class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03b5060",
   "metadata": {
    "papermill": {
     "duration": 0.02112,
     "end_time": "2023-09-26T07:47:01.493335",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.472215",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**:\n",
    "\n",
    "The `LightningWrapper` class is a PyTorch Lightning module that serves as a wrapper around your neural network model, allowing you to train, validate, and test the model using the PyTorch Lightning framework. :\n",
    "\n",
    "1. **Initialization**:\n",
    "   - The `__init__` method initializes the `LightningWrapper` object. It takes a neural network model (`model`) as a parameter.\n",
    "   - It initializes a `TileTopK` instance called `topk`. This is used for computing top-k metrics during validation.\n",
    "\n",
    "2. **Forward Pass**:\n",
    "   - The `forward` method defines how input data should be passed through the model. It delegates the forward pass to the underlying `model`.\n",
    "\n",
    "3. **Training Step**:\n",
    "   - The `training_step` method is used for computing the loss during training. It takes a batch of data (`batch`) and a batch index (`batch_idx`) as parameters.\n",
    "   - It calls the forward pass of the model with the input batch (`batch`) and retrieves the `loss` from the model's output.\n",
    "   - It returns the computed loss, which will be used for optimization.\n",
    "\n",
    "4. **Validation Step**:\n",
    "   - The `validation_step` method is similar to `training_step` but is used during the validation phase.\n",
    "   - It also calls the forward pass of the model with the input batch and retrieves the loss.\n",
    "   - Additionally, it logs the validation loss using `self.log` and updates the `TileTopK` instance with top-k metrics using `self.topk.update`.\n",
    "\n",
    "5. **Validation End**:\n",
    "   - The `on_validation_end` method is called at the end of the validation phase. It computes the top-k metric from the collected data using `self.topk.compute()` and prints it.\n",
    "   - After printing, it resets the `TileTopK` instance using `self.topk.reset()`.\n",
    "\n",
    "6. **Test Step**:\n",
    "   - The `test_step` method is used for computing the loss during testing. It takes a batch of data (`batch`) and a batch index (`batch_idx`) as parameters.\n",
    "   - It computes the predicted values (`y_hat`) by calling the model's forward pass with the input data.\n",
    "   - It also computes the loss between the predicted values and the ground truth (`y`).\n",
    "   - The test loss is logged using `self.log`.\n",
    "\n",
    "7. **Optimizer Configuration**:\n",
    "   - The `configure_optimizers` method configures the optimizer to be used during training. In this case, it sets up an AdamW optimizer for the model's parameters with a learning rate of 1e-3.\n",
    "\n",
    "The `LightningWrapper` class is designed to work seamlessly with PyTorch Lightning. It provides hooks for training, validation, and testing, and it allows you to log and track relevant metrics during these phases. This makes it easier to train and evaluate your neural network model using PyTorch Lightning's high-level abstractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7b6c840",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:01.540735Z",
     "iopub.status.busy": "2023-09-26T07:47:01.540264Z",
     "iopub.status.idle": "2023-09-26T07:47:01.555191Z",
     "shell.execute_reply": "2023-09-26T07:47:01.553735Z"
    },
    "papermill": {
     "duration": 0.042852,
     "end_time": "2023-09-26T07:47:01.558509",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.515657",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LightningWrapper(pl.LightningModule):\n",
    "    def __init__(self, model:nn.Module):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.topk = TileTopK()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        outputs = self.model(**batch)\n",
    "        return outputs['loss']\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        outputs = self.model(**batch)\n",
    "        loss = outputs['loss']\n",
    "        self.log(\"val_loss\", loss, prog_bar=True)\n",
    "        config_attn_mask = torch.ones_like(batch['config_runtime'], device=batch['config_runtime'].device)\n",
    "        self.topk.update(outputs['outputs'], batch['config_runtime'], config_attn_mask)\n",
    "        return loss\n",
    "    \n",
    "    def on_validation_end(self) -> None:\n",
    "        topk = self.topk.compute()\n",
    "        self.print(f\"topk {topk:.3f}\")\n",
    "        self.topk.reset()\n",
    "        return super().on_validation_end()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.model(x)\n",
    "        loss = self.model.loss(y_hat, y)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(self.trainer.model.parameters(), lr=1e-3)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b06599",
   "metadata": {
    "papermill": {
     "duration": 0.021579,
     "end_time": "2023-09-26T07:47:01.603019",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.581440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9295db2",
   "metadata": {
    "papermill": {
     "duration": 0.022477,
     "end_time": "2023-09-26T07:47:01.647067",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.624590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**:\n",
    "\n",
    "- `hidden_size`: The size of the hidden layers in the model. In this case, it's set to 128.\n",
    "\n",
    "- `num_attention_heads`: The number of attention heads in the model's attention mechanism. You've set it to 4, which means the model will use 4 parallel attention heads.\n",
    "\n",
    "- `num_hidden_layers`: The total number of hidden layers in the model. You've set it to 2, which means the model will have 2 layers.\n",
    "\n",
    "- `intermediate_size`: The size of the intermediate (feed-forward) layers in the model. It's set to 64.\n",
    "\n",
    "- `gradient_checkpointing`: A boolean flag indicating whether gradient checkpointing should be used. When set to `True`, gradient checkpointing can help reduce memory usage during training by recomputing intermediate activations as needed. \n",
    "\n",
    "- `margin`: A margin value used in the loss function (e.g., MarginRankingLoss). It's set to 0.1, indicating a small margin for ranking losses.\n",
    "\n",
    "- `number_permutations`: The number of permutations to be used in the loss function. This is related to how the model's outputs are compared to permutations of the inputs during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c4354e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:01.696641Z",
     "iopub.status.busy": "2023-09-26T07:47:01.695624Z",
     "iopub.status.idle": "2023-09-26T07:47:01.702566Z",
     "shell.execute_reply": "2023-09-26T07:47:01.701317Z"
    },
    "papermill": {
     "duration": 0.035884,
     "end_time": "2023-09-26T07:47:01.706143",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.670259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_kwargs = dict(hidden_size= 128,\n",
    "    num_attention_heads= 4,\n",
    "    num_hidden_layers= 2,\n",
    "    intermediate_size= 64,\n",
    "    gradient_checkpointing= True,\n",
    "    margin= 0.1,\n",
    "    number_permutations= 4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41dfe803",
   "metadata": {
    "papermill": {
     "duration": 0.023237,
     "end_time": "2023-09-26T07:47:01.751904",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.728667",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " we use this config object to create an instance of your model with the desired architecture and hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c7f3cea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:01.800405Z",
     "iopub.status.busy": "2023-09-26T07:47:01.799478Z",
     "iopub.status.idle": "2023-09-26T07:47:01.805809Z",
     "shell.execute_reply": "2023-09-26T07:47:01.804693Z"
    },
    "papermill": {
     "duration": 0.034701,
     "end_time": "2023-09-26T07:47:01.809979",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.775278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = GraphConfig(**config_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6e3a00e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:01.861831Z",
     "iopub.status.busy": "2023-09-26T07:47:01.860987Z",
     "iopub.status.idle": "2023-09-26T07:47:01.878688Z",
     "shell.execute_reply": "2023-09-26T07:47:01.877231Z"
    },
    "papermill": {
     "duration": 0.046419,
     "end_time": "2023-09-26T07:47:01.882080",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.835661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = GraphEncoder(config)\n",
    "model = LightningWrapper(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03aa0d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:01.930528Z",
     "iopub.status.busy": "2023-09-26T07:47:01.930038Z",
     "iopub.status.idle": "2023-09-26T07:47:01.962353Z",
     "shell.execute_reply": "2023-09-26T07:47:01.960841Z"
    },
    "papermill": {
     "duration": 0.061112,
     "end_time": "2023-09-26T07:47:01.966001",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.904889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = tile_df.query(\"split == 'train'\").reset_index(drop=True)\n",
    "valid_df = tile_df.query(\"split == 'valid'\").reset_index(drop=True)\n",
    "train_dataset = TileDataset(train_df, num_configs=24)\n",
    "valid_dataset = TileDataset(valid_df, num_configs=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "903d71ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:02.012810Z",
     "iopub.status.busy": "2023-09-26T07:47:02.012286Z",
     "iopub.status.idle": "2023-09-26T07:47:02.020288Z",
     "shell.execute_reply": "2023-09-26T07:47:02.018697Z"
    },
    "papermill": {
     "duration": 0.035017,
     "end_time": "2023-09-26T07:47:02.023345",
     "exception": false,
     "start_time": "2023-09-26T07:47:01.988328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, collate_fn=collate_fn, batch_size=8, num_workers=2, shuffle=True, persistent_workers=True)\n",
    "valid_dataloader = DataLoader(valid_dataset, collate_fn=collate_fn, batch_size=8, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6332c2",
   "metadata": {
    "papermill": {
     "duration": 0.022944,
     "end_time": "2023-09-26T07:47:02.067895",
     "exception": false,
     "start_time": "2023-09-26T07:47:02.044951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## `trainer_config`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3436ae",
   "metadata": {
    "papermill": {
     "duration": 0.023515,
     "end_time": "2023-09-26T07:47:02.117024",
     "exception": false,
     "start_time": "2023-09-26T07:47:02.093509",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination** :\n",
    "\n",
    "- `max_epochs`: The maximum number of training epochs.\n",
    "- `precision`: The numerical precision used for training (e.g., 32-bit floating-point precision).\n",
    "- `gradient_clip_val`: The maximum gradient value allowed during training (gradient clipping).\n",
    "- `accumulate_grad_batches`: The number of batches over which gradients are accumulated before performing an optimization step. This can be useful for simulating larger batch sizes when you have limited GPU memory.\n",
    "- `check_val_every_n_epoch`: How often to perform validation during training (every `n` epochs).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8b98460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:02.165245Z",
     "iopub.status.busy": "2023-09-26T07:47:02.164699Z",
     "iopub.status.idle": "2023-09-26T07:47:02.172104Z",
     "shell.execute_reply": "2023-09-26T07:47:02.170492Z"
    },
    "papermill": {
     "duration": 0.034824,
     "end_time": "2023-09-26T07:47:02.174886",
     "exception": false,
     "start_time": "2023-09-26T07:47:02.140062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer_config = dict(\n",
    "    max_epochs= 50,\n",
    "    precision= 32,\n",
    "    gradient_clip_val= 1.0,\n",
    "    accumulate_grad_batches= 4,\n",
    "    check_val_every_n_epoch= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47dde4",
   "metadata": {
    "papermill": {
     "duration": 0.023075,
     "end_time": "2023-09-26T07:47:02.220275",
     "exception": false,
     "start_time": "2023-09-26T07:47:02.197200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7eb73b3",
   "metadata": {
    "papermill": {
     "duration": 0.021725,
     "end_time": "2023-09-26T07:47:02.264545",
     "exception": false,
     "start_time": "2023-09-26T07:47:02.242820",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**:\n",
    "Configuring and training a PyTorch Lightning model using the specified trainer configuration and your previously defined model and data loaders.:\n",
    "\n",
    "1. `torch.set_float32_matmul_precision(\"medium\")`: This line sets the float32 matrix multiplication precision to \"medium,\" which means that PyTorch will use a medium-level precision for matrix multiplications during training. This can help control the trade-off between training speed and numerical stability.\n",
    "\n",
    "2. `trainer = pl.Trainer(**trainer_config)`: You're creating a PyTorch Lightning Trainer instance with the configuration specified in the `trainer_config` dictionary. This trainer will be used to train your model.\n",
    "\n",
    "3. `trainer.fit(model, train_dataloader, valid_dataloader)`: You're calling the `fit` method of the trainer to start the training process. This method takes the following arguments:\n",
    "   - `model`: The PyTorch Lightning model you want to train.\n",
    "   - `train_dataloader`: The data loader for training data.\n",
    "   - `valid_dataloader`: The data loader for validation data.\n",
    "\n",
    "This code will train your model for the specified number of epochs (as defined in `trainer_config`) while monitoring the validation loss and other metrics. The trainer will handle the training loop, logging, and other aspects of the training process using PyTorch Lightning's functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c811620c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T07:47:02.311692Z",
     "iopub.status.busy": "2023-09-26T07:47:02.311221Z",
     "iopub.status.idle": "2023-09-26T16:56:57.448450Z",
     "shell.execute_reply": "2023-09-26T16:56:57.445928Z"
    },
    "papermill": {
     "duration": 32995.168373,
     "end_time": "2023-09-26T16:56:57.454771",
     "exception": false,
     "start_time": "2023-09-26T07:47:02.286398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78b2fb0eeae440c8323b92a32720f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e2bd248e51458092ac814edf1a44ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5506192c5d684ef1a6e69636fa00cad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk 0.983\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446a2bc3a6d842f985466007b0a7c9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk 0.980\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc53bd05e99c434f9d92acec5f790607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk 0.989\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7820b14327634e35943dd09c18f00f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk 0.990\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71acb6f4a4024487a64b0acd6f863311",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk 0.992\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "trainer = pl.Trainer(**trainer_config,)\n",
    "trainer.fit(model, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d92955b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T16:56:57.514728Z",
     "iopub.status.busy": "2023-09-26T16:56:57.514086Z",
     "iopub.status.idle": "2023-09-26T16:56:57.525905Z",
     "shell.execute_reply": "2023-09-26T16:56:57.524322Z"
    },
    "papermill": {
     "duration": 0.049775,
     "end_time": "2023-09-26T16:56:57.530124",
     "exception": false,
     "start_time": "2023-09-26T16:56:57.480349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9962c186",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T16:56:57.581401Z",
     "iopub.status.busy": "2023-09-26T16:56:57.580473Z",
     "iopub.status.idle": "2023-09-26T16:56:57.613786Z",
     "shell.execute_reply": "2023-09-26T16:56:57.611465Z"
    },
    "papermill": {
     "duration": 0.061977,
     "end_time": "2023-09-26T16:56:57.617223",
     "exception": false,
     "start_time": "2023-09-26T16:56:57.555246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = 'test'\n",
    "test_tile_df = tile_df.query(\"split == @split\").reset_index(drop=True)\n",
    "test_tile_ds = TileDataset(test_tile_df, num_configs=-1)\n",
    "collate_fn = LayoutCollator(64, targets=split!=\"test\")\n",
    "test_dataloader = DataLoader(test_tile_ds, batch_size=1, shuffle=False, num_workers=0, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "250d6fad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T16:56:57.670953Z",
     "iopub.status.busy": "2023-09-26T16:56:57.670054Z",
     "iopub.status.idle": "2023-09-26T16:56:57.683310Z",
     "shell.execute_reply": "2023-09-26T16:56:57.681659Z"
    },
    "papermill": {
     "duration": 0.044419,
     "end_time": "2023-09-26T16:56:57.686298",
     "exception": false,
     "start_time": "2023-09-26T16:56:57.641879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model = model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1e3759",
   "metadata": {
    "papermill": {
     "duration": 0.023642,
     "end_time": "2023-09-26T16:56:57.737546",
     "exception": false,
     "start_time": "2023-09-26T16:56:57.713904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " ## `chunk_batch` function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b94f93",
   "metadata": {
    "papermill": {
     "duration": 0.024231,
     "end_time": "2023-09-26T16:56:57.787375",
     "exception": false,
     "start_time": "2023-09-26T16:56:57.763144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "** Explanation** :\n",
    "\n",
    "1. The function starts by creating an `output` dictionary, which will store the selected components of the batch. These components include 'node_opcode', 'node_feat', 'edges_adjecency', 'node_attn_mask', and 'node_config_ids'.\n",
    "\n",
    "2. Next, it slices the 'node_config_feat' component of the batch using Python's slicing notation. The slice `[:, start_idx: end_idx]` selects a portion of the 'node_config_feat' tensor, where `start_idx` is the starting index and `end_idx` is the ending index (exclusive).\n",
    "\n",
    "3. The sliced 'node_config_feat' is added to the `output` dictionary under the key 'node_config_feat'.\n",
    "\n",
    "4. Finally, the function returns the `output` dictionary, which contains the selected components of the batch along with the sliced 'node_config_feat', creating a smaller chunk of the batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d16e2bcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T16:56:57.839034Z",
     "iopub.status.busy": "2023-09-26T16:56:57.838359Z",
     "iopub.status.idle": "2023-09-26T16:56:57.846639Z",
     "shell.execute_reply": "2023-09-26T16:56:57.845194Z"
    },
    "papermill": {
     "duration": 0.036495,
     "end_time": "2023-09-26T16:56:57.849380",
     "exception": false,
     "start_time": "2023-09-26T16:56:57.812885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def chunk_batch(batch, start_idx, end_idx):\n",
    "    # Create an output dictionary to store the selected batch components.\n",
    "    output = {k: batch[k] for k in ['node_opcode', 'node_feat', 'edges_adjecency', 'node_attn_mask', 'node_config_ids']}\n",
    "    \n",
    "    # Slice the 'node_config_feat' component to create a smaller chunk.\n",
    "    output['node_config_feat'] = batch['node_config_feat'][:, start_idx: end_idx]\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5020a064",
   "metadata": {
    "papermill": {
     "duration": 0.026773,
     "end_time": "2023-09-26T16:56:57.903389",
     "exception": false,
     "start_time": "2023-09-26T16:56:57.876616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Explaination**:\n",
    "1. `pred_order = []`: You initialize an empty list to store the predicted orders.\n",
    "\n",
    "2. `for batch in tqdm(test_dataloader)`: You iterate through batches in the `test_dataloader`. `tqdm` is used to display a progress bar while iterating through the batches.\n",
    "\n",
    "3. `batch.pop('config_idxs')`: You remove the 'config_idxs' key from the batch dictionary. This is likely because 'config_idxs' is not needed for making predictions on the test set.\n",
    "\n",
    "4. `batch = {k: v.to(device) for k, v in batch.items()}`: You move the data in the batch to the specified device (e.g., GPU) for inference.\n",
    "\n",
    "5. `num_configs = batch['node_config_feat'].shape[1]`: You determine the number of configurations in the batch.\n",
    "\n",
    "6. `configs_cut_points = list(range(0, num_configs, 100)) + [num_configs]`: You create a list of cut points to divide the batch into smaller chunks. Each chunk will be processed separately.\n",
    "\n",
    "7. `chunk_order = []`: You initialize an empty list to store the predicted orders for the current chunk.\n",
    "\n",
    "8. Inside the loop over `configs_cut_points`, you split the batch into smaller chunks using the `chunk_batch` function (which is assumed to be defined elsewhere). For each chunk, you perform the following steps:\n",
    "   - You make predictions (inference) using the trained model by passing the chunked batch to `model.model(**chunked_batch)`. This returns an output dictionary.\n",
    "   - You extend the `chunk_order` list with the predicted outputs from the current chunk.\n",
    "\n",
    "9. After processing all chunks, you concatenate the predicted orders from each chunk and use `np.argsort` to find the indices that would sort the concatenated array. Then, you select the first five indices with the smallest values and append them to `pred_order`. These are your top 5 predictions for each batch.\n",
    "\n",
    "The `pred_order` list will contain the top 5 predicted orders for each batch in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78b053fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T16:56:57.956104Z",
     "iopub.status.busy": "2023-09-26T16:56:57.955654Z",
     "iopub.status.idle": "2023-09-26T17:16:56.007003Z",
     "shell.execute_reply": "2023-09-26T17:16:56.005940Z"
    },
    "papermill": {
     "duration": 1198.176533,
     "end_time": "2023-09-26T17:16:56.104641",
     "exception": false,
     "start_time": "2023-09-26T16:56:57.928108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 844/844 [19:58<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "pred_order = []\n",
    "for batch in tqdm(test_dataloader):\n",
    "    batch.pop('config_idxs')\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    num_configs = batch['node_config_feat'].shape[1]\n",
    "    configs_cut_points = list(range(0,num_configs, 100)) + [num_configs]\n",
    "    chunk_order = []\n",
    "    for start, end in zip(configs_cut_points, configs_cut_points[1:]):\n",
    "        chunked_batch = chunk_batch(batch, start, end)\n",
    "        with torch.no_grad():\n",
    "            output = model.model(**chunked_batch)\n",
    "        chunk_order.extend(output['outputs'].cpu().numpy())\n",
    "    pred_order.append(np.argsort(np.concatenate(chunk_order))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "174ce9a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T17:16:56.281227Z",
     "iopub.status.busy": "2023-09-26T17:16:56.280310Z",
     "iopub.status.idle": "2023-09-26T17:16:56.308827Z",
     "shell.execute_reply": "2023-09-26T17:16:56.307596Z"
    },
    "papermill": {
     "duration": 0.123795,
     "end_time": "2023-09-26T17:16:56.311826",
     "exception": false,
     "start_time": "2023-09-26T17:16:56.188031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TopConfigs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tile:xla:04ae9238c653f8ae08f60f2c03615f0b</td>\n",
       "      <td>746;788;688;709;554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tile:xla:85d157d3b1848c6b6fff0c633876e2e6</td>\n",
       "      <td>5560;4526;5409;1066;910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tile:xla:862900d42397d03be2762e1bf7518bea</td>\n",
       "      <td>935;287;1409;1344;161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tile:xla:0afa527a7022415fda1dd69d11e908a4</td>\n",
       "      <td>210;212;158;234;176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tile:xla:2d09e3ab92e184c561abaf8d9efe7b87</td>\n",
       "      <td>170;147;24;89;6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          ID               TopConfigs\n",
       "0  tile:xla:04ae9238c653f8ae08f60f2c03615f0b      746;788;688;709;554\n",
       "1  tile:xla:85d157d3b1848c6b6fff0c633876e2e6  5560;4526;5409;1066;910\n",
       "2  tile:xla:862900d42397d03be2762e1bf7518bea    935;287;1409;1344;161\n",
       "3  tile:xla:0afa527a7022415fda1dd69d11e908a4      210;212;158;234;176\n",
       "4  tile:xla:2d09e3ab92e184c561abaf8d9efe7b87          170;147;24;89;6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs_string = [\";\".join(map(str,elem)) for elem in pred_order]\n",
    "test_tile_df['TopConfigs'] = idxs_string\n",
    "test_tile_df = test_tile_df[['ID', 'TopConfigs']]\n",
    "test_tile_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50329fa5",
   "metadata": {
    "papermill": {
     "duration": 0.083543,
     "end_time": "2023-09-26T17:16:56.481852",
     "exception": false,
     "start_time": "2023-09-26T17:16:56.398309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d95e9",
   "metadata": {
    "papermill": {
     "duration": 0.084375,
     "end_time": "2023-09-26T17:16:56.651531",
     "exception": false,
     "start_time": "2023-09-26T17:16:56.567156",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This code essentially filters out specific rows from 'submission_df' and appends the rows from 'test_tile_df' before saving the combined DataFrame to a new CSV file named 'submission.csv'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de98a9f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-26T17:16:56.828863Z",
     "iopub.status.busy": "2023-09-26T17:16:56.827338Z",
     "iopub.status.idle": "2023-09-26T17:16:56.940441Z",
     "shell.execute_reply": "2023-09-26T17:16:56.939186Z"
    },
    "papermill": {
     "duration": 0.207161,
     "end_time": "2023-09-26T17:16:56.943542",
     "exception": false,
     "start_time": "2023-09-26T17:16:56.736381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TopConfigs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tile:xla:04ae9238c653f8ae08f60f2c03615f0b</td>\n",
       "      <td>746;788;688;709;554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tile:xla:85d157d3b1848c6b6fff0c633876e2e6</td>\n",
       "      <td>5560;4526;5409;1066;910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tile:xla:862900d42397d03be2762e1bf7518bea</td>\n",
       "      <td>935;287;1409;1344;161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tile:xla:0afa527a7022415fda1dd69d11e908a4</td>\n",
       "      <td>210;212;158;234;176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tile:xla:2d09e3ab92e184c561abaf8d9efe7b87</td>\n",
       "      <td>170;147;24;89;6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>layout:nlp:random:60880ed76de53f4d7a1b960b24f2...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>layout:nlp:random:23559853d9702baaaacbb0c83fd3...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>layout:nlp:random:f6c146fc5cf10be4f3accbaca989...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>layout:nlp:random:32531d07a084b319dce484f53a4c...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>layout:nlp:random:3a0c5517a87df8d82fd637b83298...</td>\n",
       "      <td>0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>894 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    ID  \\\n",
       "0            tile:xla:04ae9238c653f8ae08f60f2c03615f0b   \n",
       "1            tile:xla:85d157d3b1848c6b6fff0c633876e2e6   \n",
       "2            tile:xla:862900d42397d03be2762e1bf7518bea   \n",
       "3            tile:xla:0afa527a7022415fda1dd69d11e908a4   \n",
       "4            tile:xla:2d09e3ab92e184c561abaf8d9efe7b87   \n",
       "..                                                 ...   \n",
       "889  layout:nlp:random:60880ed76de53f4d7a1b960b24f2...   \n",
       "890  layout:nlp:random:23559853d9702baaaacbb0c83fd3...   \n",
       "891  layout:nlp:random:f6c146fc5cf10be4f3accbaca989...   \n",
       "892  layout:nlp:random:32531d07a084b319dce484f53a4c...   \n",
       "893  layout:nlp:random:3a0c5517a87df8d82fd637b83298...   \n",
       "\n",
       "                                            TopConfigs  \n",
       "0                                  746;788;688;709;554  \n",
       "1                              5560;4526;5409;1066;910  \n",
       "2                                935;287;1409;1344;161  \n",
       "3                                  210;212;158;234;176  \n",
       "4                                      170;147;24;89;6  \n",
       "..                                                 ...  \n",
       "889  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "890  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "891  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "892  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "893  0;1;2;3;4;5;6;7;8;9;10;11;12;13;14;15;16;17;18...  \n",
       "\n",
       "[894 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv('../input/predict-ai-model-runtime/sample_submission.csv')\n",
    "submission_df = submission_df.query(f\"ID not in {test_tile_df.ID.tolist()}\")\n",
    "submission_df = pd.concat([test_tile_df, submission_df])\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed4e44d",
   "metadata": {
    "papermill": {
     "duration": 0.09237,
     "end_time": "2023-09-26T17:16:57.127821",
     "exception": false,
     "start_time": "2023-09-26T17:16:57.035451",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Explore More! ðŸ‘€\n",
    "Thank you for exploring this notebook! If you found this notebook insightful or if it helped you in any way, I invite you to explore more of my work on my profile.\n",
    "\n",
    "ðŸ‘‰ [Visit my Profile](https://www.kaggle.com/zulqarnainali) ðŸ‘ˆ\n",
    "\n",
    "## Feedback and Gratitude ðŸ™\n",
    "We value your feedback! Your insights and suggestions are essential for our continuous improvement. If you have any comments, questions, or ideas to share, please don't hesitate to reach out.\n",
    "\n",
    "ðŸ“¬ Contact me via email: [zulqar445ali@gmail.com](mailto:zulqar445ali@gmail.com)\n",
    "\n",
    "I would like to express our heartfelt gratitude for your time and engagement. Your support motivates us to create more valuable content.\n",
    "\n",
    "Happy coding and best of luck in your data science endeavors! ðŸš€\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 34238.14772,
   "end_time": "2023-09-26T17:17:00.931406",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-26T07:46:22.783686",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "056e945169d24a3f80ae5cd7a9f17d1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "12e9d867431345eb9a0b37b9f7ccf585": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "140f2268f934420a8b0328800d1b7162": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "1f03c0a98fbc45859dc7fbd1efa84d51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e429b6bcc4ad4312b894af0506945fe1",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_e912f382c0264fb2ba2861da3943e941",
       "value": " 2/2 [00:01&lt;00:00,  1.23it/s]"
      }
     },
     "1fc73f1cd54f40cca356822f929edf7a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2276c8f7c1db4f9696ed1e094d625945",
       "max": 85.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_de75297f456f4f9db46de3984244aaa1",
       "value": 85.0
      }
     },
     "21d1f884c34741fa929e3c0c77c3ebdf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "2276c8f7c1db4f9696ed1e094d625945": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "238964bd2a2f41458082310435627a22": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "25367e76f30842ccaacf8f638d513efc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7c1f9757cd9d446e85ffca2c2f7c3c2e",
       "max": 85.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f43592d2d4404befa808b5df37ec8219",
       "value": 85.0
      }
     },
     "25dfbb8b0a154fd2a728d551d5429b4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc01f1bfe0c948c48250931714de4699",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c856591b7c9844f980fa5429b6269dbe",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "29b0bdd7a7ad497faa894c0bd3f5e963": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2abcc1456a914ede812af7c4a7b1576d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "32b00b0d468d4d04b9bfdf3d76d97932": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "349396c8f2fa4d1a921792336f375314": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3b2978200b8d410ead60004f8d99885a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6541df522949478d94c1b3eecf73872a",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_140f2268f934420a8b0328800d1b7162",
       "value": " 714/714 [11:21&lt;00:00,  1.05it/s, v_num=0, val_loss=0.0323]"
      }
     },
     "3dc189ecefb8441eb95170241b948aec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_966d0ad0ce2e49fcaff7ad0726f23338",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_5c5e1b65c72445b5ac4a23fe61081381",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "4004f9f2e15a40a4a2960934c96502eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_85aad2d4e5d34f89b7d65418c1f4ac39",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_edef6d73cf79405e9f797500e8144315",
       "value": 2.0
      }
     },
     "445e6b2acb41449498f01c4cec755d0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "446a2bc3a6d842f985466007b0a7c9f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d77a734359f2480e93e057268be22c9b",
        "IPY_MODEL_1fc73f1cd54f40cca356822f929edf7a",
        "IPY_MODEL_b487a0a4d22041a69cc3fb9a08903bf8"
       ],
       "layout": "IPY_MODEL_056e945169d24a3f80ae5cd7a9f17d1e"
      }
     },
     "450d82c4d0a64f8f88fcdac83d17e755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_5b6d12f3b0504d68bc5870d9f0578ec9",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_349396c8f2fa4d1a921792336f375314",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "48f06770927e4b629de8108c0e9f028b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2abcc1456a914ede812af7c4a7b1576d",
       "max": 714.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c0376cd8da7e43868c7b65c72fb2b6fe",
       "value": 714.0
      }
     },
     "4ab561875c8d4a0baa119868629db2e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_dbce52cbdda742d7947680af87240fc9",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_a7b013a93b9f43138150bfdbae204561",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "4ec3d72549694c4ca59a9f10cbc3c081": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a3fb97c2bbe847c1918c3931ad12c62a",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_c0a0b17ce4474f0892b8b6f0a38c156a",
       "value": "Sanity Checking DataLoader 0: 100%"
      }
     },
     "4f4a64461ed4458588b04df12ae122ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7f30d8cab8d74042a41f5aebfb70bc15",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_b883bae755e84ecdb86ee3e0107a90d7",
       "value": " 85/85 [00:24&lt;00:00,  3.48it/s]"
      }
     },
     "515e88fe783f4cf69958fd3c1fc1c3c4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_833c7b1dcc8847bda974b83234992dcc",
       "max": 85.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a053ebf5f1d84725923ae165dbb0bb94",
       "value": 85.0
      }
     },
     "517ae8898c4e4242b582ac12539fae89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ab711268f364437d8a63874b11623056",
       "max": 85.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_32b00b0d468d4d04b9bfdf3d76d97932",
       "value": 85.0
      }
     },
     "5506192c5d684ef1a6e69636fa00cad5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_25dfbb8b0a154fd2a728d551d5429b4d",
        "IPY_MODEL_e5a49b4be47042a9b79af42fe31d4f3d",
        "IPY_MODEL_77d815cd2c8744ea9f660301fa6d1267"
       ],
       "layout": "IPY_MODEL_21d1f884c34741fa929e3c0c77c3ebdf"
      }
     },
     "59cf5b247f974850b7f9a90a8967f787": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b6d12f3b0504d68bc5870d9f0578ec9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5c5e1b65c72445b5ac4a23fe61081381": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "5eabc0a2edda49ddbc220f9e57fcd6ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_c85d294e57364852b39696f7fa6b2293",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_eee9f1517ce14baa9e2ec4346cf43b6e",
       "value": "Epoch 49: 100%"
      }
     },
     "6541df522949478d94c1b3eecf73872a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "71acb6f4a4024487a64b0acd6f863311": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_450d82c4d0a64f8f88fcdac83d17e755",
        "IPY_MODEL_25367e76f30842ccaacf8f638d513efc",
        "IPY_MODEL_fed5759791c544efa5a21be214c92a20"
       ],
       "layout": "IPY_MODEL_7bececad2e854e309e0fcb09acb6fc03"
      }
     },
     "77d815cd2c8744ea9f660301fa6d1267": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_795711ec65b24aeb88255526184c37fc",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_860ca3f5473346e28095ea88e04c5dee",
       "value": " 85/85 [00:21&lt;00:00,  3.89it/s]"
      }
     },
     "7820b14327634e35943dd09c18f00f62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3dc189ecefb8441eb95170241b948aec",
        "IPY_MODEL_515e88fe783f4cf69958fd3c1fc1c3c4",
        "IPY_MODEL_a283360fc9664d64bee5a01a06b587bc"
       ],
       "layout": "IPY_MODEL_7fc943d9be354105adb109e25dd34d07"
      }
     },
     "795711ec65b24aeb88255526184c37fc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7b31ac88c37e4a38903a94d7335b1594": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7bececad2e854e309e0fcb09acb6fc03": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "7c1f9757cd9d446e85ffca2c2f7c3c2e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f30d8cab8d74042a41f5aebfb70bc15": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7fc943d9be354105adb109e25dd34d07": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "833c7b1dcc8847bda974b83234992dcc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85aad2d4e5d34f89b7d65418c1f4ac39": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "860ca3f5473346e28095ea88e04c5dee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "876d3d22406c44c4a65466999427ff25": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "89374d0848c4420e9820940a94c66272": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "966d0ad0ce2e49fcaff7ad0726f23338": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a053ebf5f1d84725923ae165dbb0bb94": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a283360fc9664d64bee5a01a06b587bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_89374d0848c4420e9820940a94c66272",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_f5add266ad6c4c2aa54011a2044540ce",
       "value": " 85/85 [00:25&lt;00:00,  3.37it/s]"
      }
     },
     "a3fb97c2bbe847c1918c3931ad12c62a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a7b013a93b9f43138150bfdbae204561": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ab711268f364437d8a63874b11623056": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b0840fb79fba42eba6b2e92388049765": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": "hidden",
       "width": "100%"
      }
     },
     "b487a0a4d22041a69cc3fb9a08903bf8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_29b0bdd7a7ad497faa894c0bd3f5e963",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d6da77a2ce874606843c4a7ee86fb91e",
       "value": " 85/85 [00:26&lt;00:00,  3.22it/s]"
      }
     },
     "b78b2fb0eeae440c8323b92a32720f29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4ec3d72549694c4ca59a9f10cbc3c081",
        "IPY_MODEL_4004f9f2e15a40a4a2960934c96502eb",
        "IPY_MODEL_1f03c0a98fbc45859dc7fbd1efa84d51"
       ],
       "layout": "IPY_MODEL_b0840fb79fba42eba6b2e92388049765"
      }
     },
     "b883bae755e84ecdb86ee3e0107a90d7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b8883233cdfd43d3ba5fc823c7a722c5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": "2",
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c0376cd8da7e43868c7b65c72fb2b6fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c0a0b17ce4474f0892b8b6f0a38c156a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c856591b7c9844f980fa5429b6269dbe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c85d294e57364852b39696f7fa6b2293": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc01f1bfe0c948c48250931714de4699": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6da77a2ce874606843c4a7ee86fb91e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "d77a734359f2480e93e057268be22c9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_59cf5b247f974850b7f9a90a8967f787",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_876d3d22406c44c4a65466999427ff25",
       "value": "Validation DataLoader 0: 100%"
      }
     },
     "d924ccf15eea43048182f89199a4f329": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": "inline-flex",
       "flex": null,
       "flex_flow": "row wrap",
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": "100%"
      }
     },
     "dbce52cbdda742d7947680af87240fc9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dc53bd05e99c434f9d92acec5f790607": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4ab561875c8d4a0baa119868629db2e4",
        "IPY_MODEL_517ae8898c4e4242b582ac12539fae89",
        "IPY_MODEL_4f4a64461ed4458588b04df12ae122ed"
       ],
       "layout": "IPY_MODEL_238964bd2a2f41458082310435627a22"
      }
     },
     "de75297f456f4f9db46de3984244aaa1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e2e2bd248e51458092ac814edf1a44ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5eabc0a2edda49ddbc220f9e57fcd6ff",
        "IPY_MODEL_48f06770927e4b629de8108c0e9f028b",
        "IPY_MODEL_3b2978200b8d410ead60004f8d99885a"
       ],
       "layout": "IPY_MODEL_d924ccf15eea43048182f89199a4f329"
      }
     },
     "e429b6bcc4ad4312b894af0506945fe1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5a49b4be47042a9b79af42fe31d4f3d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b8883233cdfd43d3ba5fc823c7a722c5",
       "max": 85.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_445e6b2acb41449498f01c4cec755d0a",
       "value": 85.0
      }
     },
     "e912f382c0264fb2ba2861da3943e941": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "edef6d73cf79405e9f797500e8144315": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "eee9f1517ce14baa9e2ec4346cf43b6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f43592d2d4404befa808b5df37ec8219": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f5add266ad6c4c2aa54011a2044540ce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "fed5759791c544efa5a21be214c92a20": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_12e9d867431345eb9a0b37b9f7ccf585",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_7b31ac88c37e4a38903a94d7335b1594",
       "value": " 85/85 [00:28&lt;00:00,  2.95it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
